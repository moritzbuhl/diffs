Index: arch/amd64/amd64/kasan.c
===================================================================
RCS file: arch/amd64/amd64/kasan.c
diff -N arch/amd64/amd64/kasan.c
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ arch/amd64/amd64/kasan.c	26 Apr 2023 12:51:26 -0000
@@ -0,0 +1,102 @@
+/*	$OpenBSD: kasan.c $	*/
+
+#include <sys/param.h>
+#include <sys/proc.h>
+#include <sys/systm.h>
+
+#include <uvm/uvm_extern.h>
+
+#include <machine/cpu.h>
+#include <machine/pmap.h>
+#include <machine/segments.h>
+#include <machine/vmmvar.h>
+
+#include <sys/kasan.h>
+
+#define rounddown(x, y)		(((x) / (y)) * (y))
+
+static paddr_t
+get_physpage(void)
+{
+	struct vm_page *ptp;
+	struct pmap *kpm = pmap_kernel();
+	paddr_t paddr;
+
+	ptp = uvm_pagealloc(NULL, 0, NULL, UVM_PGA_USERESERVE | UVM_PGA_ZERO);
+	if (ptp == NULL)
+		panic("%s: out of memory", __func__);
+
+	atomic_clearbits_int(&ptp->pg_flags, PG_BUSY);
+	ptp->wire_count = 1;
+	paddr = VM_PAGE_TO_PHYS(ptp);
+
+	kpm->pm_stats.resident_count++;
+
+	return (paddr);
+}
+
+void
+kasan_shadow_map_page(vaddr_t va)
+{
+	paddr_t pg;
+
+	if (!pmap_valid_entry(L4_BASE[pl4_i(va)])) {
+		pg = get_physpage();
+		L4_BASE[pl4_i(va)] = pg | PG_KW | pg_nx | PG_V;
+	}
+	if (!pmap_valid_entry(L3_BASE[pl3_i(va)])) {
+		pg = get_physpage();
+		L3_BASE[pl3_i(va)] = pg | PG_KW | pg_nx | PG_V;
+	}
+	if (!pmap_valid_entry(L2_BASE[pl2_i(va)])) {
+		pg = get_physpage();
+		L2_BASE[pl2_i(va)] = pg | PG_KW | pg_nx | PG_V;
+	}
+	if (!pmap_valid_entry(L1_BASE[pl1_i(va)])) {
+		pg = get_physpage();
+		L1_BASE[pl1_i(va)] = pg | PG_KW | pg_g_kern | pg_nx | PG_V;
+	}
+}
+
+/*
+ * Allocate the necessary stuff in the shadow, so that we can monitor the
+ * passed area.
+ */
+void
+kasan_shadow_map(vaddr_t addr, size_t size)
+{
+	size_t sz, npages, i;
+	vaddr_t va;
+
+	va = (vaddr_t)kasan_addr_to_shad(addr);
+	sz = roundup(size, KASAN_SHADOW_SCALE_SIZE) / KASAN_SHADOW_SCALE_SIZE;
+	va = rounddown(va, PAGE_SIZE);
+	npages = roundup(sz, PAGE_SIZE) / PAGE_SIZE;
+
+	KASSERT(va >= KASAN_SHADOW_START && va < KASAN_SHADOW_END);
+
+	for (i = 0; i < npages; i++) {
+		kasan_shadow_map_page(va + i * PAGE_SIZE);
+	}
+}
+
+void
+kasan_ctors(void)
+{
+	extern uint64_t __CTOR_LIST__, __CTOR_END__;
+	size_t nentries, i;
+	uint64_t *ptr;
+
+	nentries = ((size_t)&__CTOR_END__ - (size_t)&__CTOR_LIST__) /
+	    sizeof(uintptr_t);
+
+	ptr = &__CTOR_LIST__;
+	for (i = 0; i < nentries; i++) {
+		void (*func)(void);
+
+		func = (void *)(*ptr);
+		(*func)();
+
+		ptr++;
+	}
+}
Index: arch/amd64/amd64/machdep.c
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/machdep.c,v
retrieving revision 1.284
diff -u -p -r1.284 machdep.c
--- arch/amd64/amd64/machdep.c	29 Nov 2022 21:41:39 -0000	1.284
+++ arch/amd64/amd64/machdep.c	26 Apr 2023 12:47:52 -0000
@@ -100,6 +100,7 @@
 #include <machine/mpbiosvar.h>
 #include <machine/kcore.h>
 #include <machine/tss.h>
+#include <machine/kasan.h>
 
 #include <dev/isa/isareg.h>
 #include <dev/ic/i8042reg.h>
@@ -1679,6 +1680,9 @@ init_x86_64(paddr_t first_avail)
 		}
 	}
 
+#ifdef KASAN
+	kasan_init();
+#endif
 	pmap_growkernel(VM_MIN_KERNEL_ADDRESS + 32 * 1024 * 1024);
 
 	pmap_kenter_pa(idt_vaddr, idt_paddr, PROT_READ | PROT_WRITE);
Index: arch/amd64/conf/files.amd64
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/files.amd64,v
retrieving revision 1.107
diff -u -p -r1.107 files.amd64
--- arch/amd64/conf/files.amd64	14 Jan 2023 12:11:10 -0000	1.107
+++ arch/amd64/conf/files.amd64	25 Apr 2023 19:36:43 -0000
@@ -10,6 +10,7 @@ file	arch/amd64/amd64/gdt.c			multiproce
 file	arch/amd64/amd64/machdep.c
 file	arch/amd64/amd64/hibernate_machdep.c	hibernate
 file	arch/amd64/amd64/identcpu.c
+file	arch/amd64/amd64/kasan.c		kasan
 file	arch/amd64/amd64/tsc.c
 file	arch/amd64/amd64/via.c
 file	arch/amd64/amd64/locore.S
Index: arch/amd64/conf/ld.script
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/ld.script,v
retrieving revision 1.19
diff -u -p -r1.19 ld.script
--- arch/amd64/conf/ld.script	7 Nov 2022 01:41:57 -0000	1.19
+++ arch/amd64/conf/ld.script	25 Apr 2023 20:13:16 -0000
@@ -85,6 +85,10 @@ SECTIONS
 	{
 		__rodata_start = ABSOLUTE(.);
 		*(.rodata .rodata.*)
+		. = ALIGN(64);
+		__CTOR_LIST__ = .;
+		*(.ctors)
+		__CTOR_END__ = .;
 		. = ALIGN(8);
 		__nofault_start = ABSOLUTE(.);
 		*(.nofault.*) *(.nofault)
Index: arch/amd64/include/kasan.h
===================================================================
RCS file: arch/amd64/include/kasan.h
diff -N arch/amd64/include/kasan.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ arch/amd64/include/kasan.h	26 Apr 2023 12:16:04 -0000
@@ -0,0 +1,10 @@
+/*	$OpenBSD: kasan.h $	*/
+
+#ifndef _MACHINE_KASAN_H_
+#define _MACHINE_KASAN_H_
+
+void	kasan_init(void);
+void	kasan_shadow_map(vaddr_t, size_t);
+void	kasan_ctors(void);
+
+#endif /* !_MACHINE_KASAN_H_ */
Index: arch/amd64/include/pmap.h
===================================================================
RCS file: /cvs/src/sys/arch/amd64/include/pmap.h,v
retrieving revision 1.86
diff -u -p -r1.86 pmap.h
--- arch/amd64/include/pmap.h	13 Apr 2023 15:23:21 -0000	1.86
+++ arch/amd64/include/pmap.h	25 Apr 2023 20:02:02 -0000
@@ -145,11 +145,13 @@
 #define NUM_L4_SLOT_DIRECT	4
 #define L4_SLOT_DIRECT		(L4_SLOT_KERNBASE - NUM_L4_SLOT_DIRECT)
 #define L4_SLOT_EARLY		(L4_SLOT_DIRECT - 1)
+#define L4_SLOT_KASAN		(L4_SLOT_DIRECT - 2)
 
 #define PDIR_SLOT_KERN		L4_SLOT_KERN
 #define PDIR_SLOT_PTE		L4_SLOT_PTE
 #define PDIR_SLOT_DIRECT	L4_SLOT_DIRECT
 #define PDIR_SLOT_EARLY		L4_SLOT_EARLY
+#define PDIR_SLOT_KASAN		L4_SLOT_KASAN
 
 /*
  * the following defines give the virtual addresses of various MMU
Index: conf/files
===================================================================
RCS file: /cvs/src/sys/conf/files,v
retrieving revision 1.723
diff -u -p -r1.723 files
--- conf/files	4 Apr 2023 00:38:37 -0000	1.723
+++ conf/files	25 Apr 2023 19:35:36 -0000
@@ -732,6 +732,7 @@ file kern/subr_evcount.c
 file kern/subr_extent.c
 file kern/subr_suspend.c		suspend
 file kern/subr_hibernate.c		hibernate
+file kern/subr_kasan.c			kasan
 file kern/subr_kubsan.c			kubsan
 file kern/subr_log.c
 file kern/subr_percpu.c
Index: kern/kern_malloc.c
===================================================================
RCS file: /cvs/src/sys/kern/kern_malloc.c,v
retrieving revision 1.148
diff -u -p -r1.148 kern_malloc.c
--- kern/kern_malloc.c	14 Aug 2022 01:58:27 -0000	1.148
+++ kern/kern_malloc.c	26 Apr 2023 13:11:49 -0000
@@ -50,6 +50,11 @@
 #include <ddb/db_output.h>
 #endif
 
+#ifdef KASAN
+#include <machine/vmmvar.h>
+#include <sys/kasan.h>
+#endif
+
 static
 #ifndef SMALL_KERNEL
 __inline__
@@ -165,6 +170,11 @@ malloc(size_t size, int type, int flags)
 	int freshalloc;
 	char *savedtype;
 #endif
+#ifdef KASAN
+	size_t origsz = size;
+
+	kasan_add_redzone(&size);
+#endif
 #ifdef KMEMSTATS
 	struct kmemstats *ksp = &kmemstats[type];
 	int wake;
@@ -361,6 +371,7 @@ out:
 
 	TRACEPOINT(uvm, malloc, type, va, size, flags);
 
+	kasan_alloc((vaddr_t)va, origsz, size);
 	return (va);
 }
 
@@ -378,6 +389,9 @@ free(void *addr, int type, size_t freeds
 #ifdef DIAGNOSTIC
 	long alloc;
 #endif
+#ifdef KASAN
+	kasan_add_redzone(&freedsize);
+#endif
 #ifdef KMEMSTATS
 	struct kmemstats *ksp = &kmemstats[type];
 	int wake;
@@ -494,6 +508,9 @@ free(void *addr, int type, size_t freeds
 #endif
 	XSIMPLEQ_INSERT_TAIL(&kbp->kb_freelist, freep, kf_flist);
 	mtx_leave(&malloc_mtx);
+#ifdef KASAN
+	kasan_free((vaddr_t)addr, size);
+#endif
 #ifdef KMEMSTATS
 	if (wake)
 		wakeup(ksp);
Index: kern/subr_kasan.c
===================================================================
RCS file: kern/subr_kasan.c
diff -N kern/subr_kasan.c
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ kern/subr_kasan.c	26 Apr 2023 13:05:30 -0000
@@ -0,0 +1,392 @@
+/*	$OpenBSD: subr_kasan.c $	*/
+
+#include <sys/param.h>
+#include <sys/proc.h>
+#include <sys/tree.h>
+#include <sys/types.h>
+#include <sys/systm.h>
+
+#include <uvm/uvm_extern.h>
+
+#include <machine/kasan.h>
+#include <machine/cpu.h>
+#include <machine/pmap.h>
+#include <machine/segments.h>
+#include <machine/vmmvar.h>
+
+#include <../sys/kasan.h>
+
+#define __RET_ADDR	(vaddr_t)__builtin_return_address(0)
+
+#define ADDR_CROSSES_SCALE_BOUNDARY(addr, size) 		\
+	(addr >> KASAN_SHADOW_SCALE_SHIFT) !=			\
+	    ((addr + size - 1) >> KASAN_SHADOW_SCALE_SHIFT)
+
+void kasan_init(void);
+
+static int kasan_enabled = 0;
+
+static int
+kasan_unsupported(vaddr_t addr)
+{
+	return (addr >= VM_MIN_KERNEL_ADDRESS ||
+	    addr < VM_MAX_KERNEL_ADDRESS);
+}
+
+/*
+ * Create the shadow mapping. We don't create the 'User' area, because we
+ * exclude it from the monitoring. The 'Main' area is created dynamically
+ * in pmap_growkernel.
+ */
+void
+kasan_init(void)
+{
+	kasan_enabled = 1;
+
+	/* Call the ASAN constructors. */
+	kasan_ctors();
+}
+
+static void
+kasan_report(vaddr_t addr, size_t size, int write, vaddr_t rip)
+{
+	printf("KASAN: unregistered access at 0x%lx: "
+	    "%s of %lu byte%s from 0x%lx\n", rip,
+	    (write ? "write" : "read"), size, (size > 1 ? "s" : ""), addr);
+}
+
+static void
+kasan_shadow_fill(vaddr_t addr, size_t size, uint8_t val)
+{
+	char *shad;
+
+	if (!kasan_enabled)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	KASSERT(addr % KASAN_SHADOW_SCALE_SIZE == 0);
+	KASSERT(size % KASAN_SHADOW_SCALE_SIZE == 0);
+
+	shad = kasan_addr_to_shad(addr);
+	size = size >> KASAN_SHADOW_SCALE_SHIFT;
+
+	__builtin_memset(shad, val, size);
+}
+
+static inline void
+kasan_shadow_1byte_markvalid(vaddr_t addr)
+{
+	char *byte = kasan_addr_to_shad(addr);
+	char last = (addr & KASAN_SHADOW_MASK) + 1;
+
+	*byte = last;
+}
+
+void
+kasan_add_redzone(size_t *size)
+{
+	*size = roundup(*size, KASAN_SHADOW_SCALE_SIZE);
+	*size += KASAN_SHADOW_SCALE_SIZE;
+}
+
+static void
+kasan_markmem(vaddr_t addr, size_t size, int valid)
+{
+	size_t i;
+
+	KASSERT(addr % KASAN_SHADOW_SCALE_SIZE == 0);
+
+	if (valid) {
+		for (i = 0; i < size; i++)
+			kasan_shadow_1byte_markvalid(addr + i);
+	} else {
+		KASSERT(size % KASAN_SHADOW_SCALE_SIZE == 0);
+		kasan_shadow_fill(addr, size, KASAN_MEMORY_REDZONE);
+	}
+}
+
+void
+kasan_alloc(vaddr_t addr, size_t size, size_t sz_with_redz)
+{
+	if (!kasan_enabled)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	kasan_markmem(addr, sz_with_redz, 0);
+	kasan_markmem(addr, size, 1);
+}
+
+void
+kasan_free(vaddr_t addr, size_t sz_with_redz)
+{
+	if (!kasan_enabled)
+		return;
+	if (sz_with_redz == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	kasan_markmem(addr, sz_with_redz, 1);
+}
+
+static inline int
+kasan_shadow_1byte_isvalid(vaddr_t addr)
+{
+	char *byte = kasan_addr_to_shad(addr);
+	char last = (addr & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_2byte_isvalid(vaddr_t addr)
+{
+	char *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 2)) {
+		return (kasan_shadow_1byte_isvalid(addr) &&
+		    kasan_shadow_1byte_isvalid(addr + 1));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 1) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_4byte_isvalid(vaddr_t addr)
+{
+	char *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 4)) {
+		return (kasan_shadow_2byte_isvalid(addr) &&
+		    kasan_shadow_2byte_isvalid(addr + 2));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 3) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_8byte_isvalid(vaddr_t addr)
+{
+	int8_t *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 8)) {
+		return (kasan_shadow_4byte_isvalid(addr) &&
+		    kasan_shadow_4byte_isvalid(addr + 4));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 7) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_Nbyte_isvalid(vaddr_t addr, size_t size)
+{
+	size_t i;
+
+	for (i = 0; i < size; i++) {
+		if (!kasan_shadow_1byte_isvalid(addr + i))
+			return 0;
+	}
+
+	return 1;
+}
+
+static inline void
+kasan_shadow_check(unsigned long addr, size_t size, int write, vaddr_t retaddr)
+{
+	int valid;
+
+	if (!kasan_enabled)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	if (__builtin_constant_p(size)) {
+		switch (size) {
+		case 1:
+			valid = kasan_shadow_1byte_isvalid(addr);
+			break;
+		case 2:
+			valid = kasan_shadow_2byte_isvalid(addr);
+			break;
+		case 4:
+			valid = kasan_shadow_4byte_isvalid(addr);
+			break;
+		case 8:
+			valid = kasan_shadow_8byte_isvalid(addr);
+			break;
+		default:
+			valid = kasan_shadow_Nbyte_isvalid(addr, size);
+			break;
+		}
+	} else {
+		valid = kasan_shadow_Nbyte_isvalid(addr, size);
+	}
+
+	if (!valid) {
+		kasan_report(addr, size, write, retaddr);
+	}
+}
+
+void *
+kasan_memcpy(void *dst, const void *src, size_t len)
+{
+	kasan_shadow_check((vaddr_t)src, len, 0, __RET_ADDR);
+	kasan_shadow_check((vaddr_t)dst, len, 1, __RET_ADDR);
+	return __builtin_memcpy(dst, src, len);
+}
+
+int
+kasan_memcmp(const void *b1, const void *b2, size_t len)
+{
+	kasan_shadow_check((vaddr_t)b1, len, 0, __RET_ADDR);
+	kasan_shadow_check((vaddr_t)b2, len, 0, __RET_ADDR);
+	return __builtin_memcmp(b1, b2, len);
+}
+
+void *
+kasan_memset(void *b, int c, size_t len)
+{
+	kasan_shadow_check((vaddr_t)b, len, 1, __RET_ADDR);
+	return __builtin_memset(b, c, len);
+}
+
+static void
+kasan_register_global(struct __asan_global *global)
+{
+	size_t aligned_size = roundup(global->size, KASAN_SHADOW_SCALE_SIZE);
+
+	/* Poison the redzone following the var. */
+	kasan_shadow_fill((vaddr_t)((uintptr_t)global->beg + aligned_size),
+	    global->size_with_redzone - aligned_size, KASAN_GLOBAL_REDZONE);
+}
+
+void
+__asan_register_globals(struct __asan_global *globals, size_t size)
+{
+	size_t i;
+	for (i = 0; i < size; i++) {
+		kasan_register_global(&globals[i]);
+	}
+}
+
+void
+__asan_unregister_globals(struct __asan_global *globals, size_t size)
+{
+}
+
+#define ASAN_LOAD_STORE(size)					\
+	void __asan_load##size(unsigned long);			\
+	void __asan_load##size(unsigned long addr)		\
+	{							\
+		kasan_shadow_check(addr, size, 0, __RET_ADDR);\
+	} 							\
+	void __asan_load##size##_noabort(unsigned long);	\
+	void __asan_load##size##_noabort(unsigned long addr)	\
+	{							\
+		kasan_shadow_check(addr, size, 0, __RET_ADDR);\
+	}							\
+	void __asan_store##size(unsigned long);			\
+	void __asan_store##size(unsigned long addr)		\
+	{							\
+		kasan_shadow_check(addr, size, 1, __RET_ADDR);\
+	}							\
+	void __asan_store##size##_noabort(unsigned long);	\
+	void __asan_store##size##_noabort(unsigned long addr)	\
+	{							\
+		kasan_shadow_check(addr, size, 1, __RET_ADDR);\
+	}
+
+ASAN_LOAD_STORE(1);
+ASAN_LOAD_STORE(2);
+ASAN_LOAD_STORE(4);
+ASAN_LOAD_STORE(8);
+ASAN_LOAD_STORE(16);
+
+void
+__asan_loadN(unsigned long addr, size_t size)
+{
+	kasan_shadow_check(addr, size, 0, __RET_ADDR);
+}
+
+void
+__asan_loadN_noabort(unsigned long addr, size_t size)
+{
+	kasan_shadow_check(addr, size, 0, __RET_ADDR);
+}
+
+void
+__asan_storeN(unsigned long addr, size_t size)
+{
+	kasan_shadow_check(addr, size, 1, __RET_ADDR);
+}
+
+void
+__asan_storeN_noabort(unsigned long addr, size_t size)
+{
+	kasan_shadow_check(addr, size, 1, __RET_ADDR);
+}
+
+void
+__asan_handle_no_return(void)
+{
+	/* nothing */
+}
+
+void
+__asan_poison_stack_memory(const void *addr, size_t size)
+{
+	vaddr_t va = (vaddr_t)addr;
+	KASSERT(va % KASAN_SHADOW_SCALE_SIZE == 0);
+	kasan_shadow_fill(va, size, KASAN_USE_AFTER_SCOPE);
+}
+
+void
+__asan_unpoison_stack_memory(const void *addr, size_t size)
+{
+	vaddr_t va = (vaddr_t)addr;
+	KASSERT(va % KASAN_SHADOW_SCALE_SIZE == 0);
+	kasan_shadow_fill(va, size, 0);
+}
+
+void
+__asan_alloca_poison(unsigned long addr, size_t size)
+{
+	panic("%s: impossible!", __func__);
+}
+
+void
+__asan_allocas_unpoison(const void *stack_top, const void *stack_bottom)
+{
+	panic("%s: impossible!", __func__);
+}
+
+#define ASAN_SET_SHADOW(byte) \
+	void __asan_set_shadow_##byte(void *, size_t);			\
+	void __asan_set_shadow_##byte(void *addr, size_t size)		\
+	{								\
+		__builtin_memset((void *)addr, 0x##byte, size);		\
+	}
+
+ASAN_SET_SHADOW(00);
+ASAN_SET_SHADOW(f1);
+ASAN_SET_SHADOW(f2);
+ASAN_SET_SHADOW(f3);
+ASAN_SET_SHADOW(f5);
+ASAN_SET_SHADOW(f8);
Index: sys/kasan.h
===================================================================
RCS file: sys/kasan.h
diff -N sys/kasan.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ sys/kasan.h	26 Apr 2023 11:40:11 -0000
@@ -0,0 +1,82 @@
+/*	$OpenBSD: kasan.h $	*/
+
+#ifndef _SYS_KASAN_H_
+#define _SYS_KASAN_H_
+
+#define KASAN_SHADOW_SCALE_SHIFT	3
+#define KASAN_SHADOW_SCALE_SIZE		(1UL << KASAN_SHADOW_SCALE_SHIFT)
+#define KASAN_SHADOW_MASK		(KASAN_SHADOW_SCALE_SIZE - 1)
+
+#define KASAN_SHADOW_SIZE	(VM_MAX_KERNEL_ADDRESS - VM_MIN_KERNEL_ADDRESS)
+#define KASAN_SHADOW_START	(VA_SIGN_NEG((L4_SLOT_KASAN * NBPD_L4)))
+#define KASAN_SHADOW_END	(KASAN_SHADOW_START + KASAN_SHADOW_SIZE)
+
+/* Our redzone values. */
+#define KASAN_GLOBAL_REDZONE	0xFA
+#define KASAN_MEMORY_REDZONE	0xFB
+
+/* Stack redzone shadow values. Part of the compiler ABI. */
+#define KASAN_STACK_LEFT	0xF1
+#define KASAN_STACK_MID		0xF2
+#define KASAN_STACK_RIGHT	0xF3
+#define KASAN_STACK_PARTIAL	0xF4
+#define KASAN_USE_AFTER_SCOPE	0xF8
+
+inline char *
+kasan_addr_to_shad(vaddr_t va)
+{
+	return (char *)(KASAN_SHADOW_START +
+	    ((va - VM_MIN_KERNEL_ADDRESS) >> KASAN_SHADOW_SCALE_SHIFT));
+}
+
+void	 kasan_add_redzone(size_t *);
+void	 kasan_alloc(vaddr_t, size_t, size_t);
+void	 kasan_free(vaddr_t, size_t);
+
+struct __asan_global;
+
+void __asan_register_globals(struct __asan_global *, size_t);
+void __asan_unregister_globals(struct __asan_global *, size_t);
+
+void __asan_loadN(unsigned long, size_t);
+void __asan_loadN_noabort(unsigned long, size_t);
+void __asan_storeN(unsigned long, size_t);
+void __asan_storeN_noabort(unsigned long, size_t);
+void __asan_handle_no_return(void);
+void __asan_poison_stack_memory(const void *, size_t);
+void __asan_unpoison_stack_memory(const void *, size_t);
+void __asan_alloca_poison(unsigned long, size_t);
+void __asan_allocas_unpoison(const void *, const void *);
+
+#if defined(__clang__) && (__clang_major__ - 0 >= 6)
+#define ASAN_ABI_VERSION	8
+#elif __GNUC_PREREQ__(7, 1) && !defined(__clang__)
+#define ASAN_ABI_VERSION	8
+#elif __GNUC_PREREQ__(6, 1) && !defined(__clang__)
+#define ASAN_ABI_VERSION	6
+#else
+#error "Unsupported compiler version"
+#endif
+
+/*
+ * Part of the compiler ABI.
+ */
+struct __asan_global_source_location {
+	const char *filename;
+	int line_no;
+	int column_no;
+};
+struct __asan_global {
+	const void *beg;		/* address of the global variable */
+	size_t size;			/* size of the global variable */
+	size_t size_with_redzone;	/* size with the redzone */
+	const void *name;		/* name of the variable */
+	const void *module_name;	/* name of the module where the var is declared */
+	unsigned long has_dynamic_init;	/* the var has dyn initializer (c++) */
+	struct __asan_global_source_location *location;
+#if ASAN_ABI_VERSION >= 7
+	uintptr_t odr_indicator;	/* the address of the ODR indicator symbol */
+#endif
+};
+
+#endif /* !_SYS_KASAN_H_ */
Index: sys/systm.h
===================================================================
RCS file: /cvs/src/sys/sys/systm.h,v
retrieving revision 1.161
diff -u -p -r1.161 systm.h
--- sys/systm.h	31 Jan 2023 15:18:56 -0000	1.161
+++ sys/systm.h	26 Apr 2023 11:37:26 -0000
@@ -383,10 +383,20 @@ extern int (*mountroot)(void);
 
 #include <lib/libkern/libkern.h>
 
+#ifdef KASAN
+void	*kasan_memset(void *, int, size_t);
+int	kasan_memcmp(const void *, const void *, size_t);
+void	*kasan_memcpy(void *, const void *, size_t);
+#define bzero(b, n)		kasan_memset((b), 0, (n))
+#define memcmp(b1, b2, n)	kasan_memcmp((b1), (b2), (n))
+#define memcpy(d, s, n)		kasan_memcpy((d), (s), (n))
+#define memset(b, c, n)		kasan_memset((b), (c), (n))
+#else
 #define bzero(b, n)		__builtin_bzero((b), (n))
 #define memcmp(b1, b2, n)	__builtin_memcmp((b1), (b2), (n))
 #define memcpy(d, s, n)		__builtin_memcpy((d), (s), (n))
 #define memset(b, c, n)		__builtin_memset((b), (c), (n))
+#endif
 #if (defined(__GNUC__) && __GNUC__ >= 4)
 #define memmove(d, s, n)	__builtin_memmove((d), (s), (n))
 #endif
