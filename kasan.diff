Index: arch/amd64/amd64/acpi_machdep.c
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/acpi_machdep.c,v
diff -u -p -r1.110 acpi_machdep.c
--- arch/amd64/amd64/acpi_machdep.c	29 May 2024 12:21:33 -0000	1.110
+++ arch/amd64/amd64/acpi_machdep.c	14 Jul 2024 19:07:29 -0000
@@ -52,6 +52,8 @@
 #include <machine/i82489var.h>
 #endif
 
+#include <sys/kasan.h>
+
 extern u_char acpi_real_mode_resume[], acpi_resume_end[];
 extern u_char acpi_tramp_data_start[], acpi_tramp_data_end[];
 extern u_int32_t acpi_pdirpa;
@@ -119,6 +121,9 @@ acpi_map(paddr_t pa, size_t len, struct 
 
 	do {
 		pmap_kenter_pa(va, pgpa, PROT_READ | PROT_WRITE);
+#ifdef KASAN
+		kasan_alloc(va, NBPG, NBPG);
+#endif
 		va += NBPG;
 		pgpa += NBPG;
 	} while (pgpa < endpa);
Index: arch/amd64/amd64/cpu.c
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/cpu.c,v
diff -u -p -r1.190 cpu.c
--- arch/amd64/amd64/cpu.c	7 Jun 2024 16:53:35 -0000	1.190
+++ arch/amd64/amd64/cpu.c	14 Jul 2024 19:07:29 -0000
@@ -96,6 +96,10 @@
 #include <machine/pio.h>
 #include <machine/vmmvar.h>
 
+#ifdef KASAN
+#include <sys/kasan.h>
+#endif
+
 #if NLAPIC > 0
 #include <machine/i82489reg.h>
 #include <machine/i82489var.h>
@@ -647,6 +651,9 @@ cpu_attach(struct device *parent, struct
 		return;
 	}
 	pcb = ci->ci_idle_pcb = (struct pcb *) kstack;
+#ifdef KASAN
+	kasan_alloc(kstack, USPACE, USPACE);
+#endif
 	memset(pcb, 0, USPACE);
 
 	pcb->pcb_kstack = kstack + USPACE - 16;
Index: arch/amd64/amd64/kasan.c
===================================================================
RCS file: arch/amd64/amd64/kasan.c
diff -N arch/amd64/amd64/kasan.c
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ arch/amd64/amd64/kasan.c	14 Jul 2024 19:07:29 -0000
@@ -0,0 +1,37 @@
+/*	$OpenBSD$	*/
+
+#include <sys/param.h>
+#include <sys/proc.h>
+#include <sys/systm.h>
+
+#include <uvm/uvm_extern.h>
+
+#include <machine/cpu.h>
+#include <machine/pmap.h>
+#include <machine/segments.h>
+#include <machine/vmmvar.h>
+
+#include <sys/kasan.h>
+
+void	kasan_enter_shad_multi(vaddr_t, size_t);
+
+void
+kasan_ctors(void)
+{
+	extern uint64_t __CTOR_LIST__, __CTOR_END__;
+	size_t nentries, i;
+	uint64_t *ptr;
+
+	nentries = ((size_t)&__CTOR_END__ - (size_t)&__CTOR_LIST__) /
+	    sizeof(uintptr_t);
+
+	ptr = &__CTOR_LIST__;
+	for (i = 0; i < nentries; i++) {
+		void (*func)(void);
+
+		func = (void *)(*ptr);
+		(*func)();
+
+		ptr++;
+	}
+}
Index: arch/amd64/amd64/machdep.c
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/machdep.c,v
diff -u -p -r1.295 machdep.c
--- arch/amd64/amd64/machdep.c	26 Jun 2024 01:40:49 -0000	1.295
+++ arch/amd64/amd64/machdep.c	14 Jul 2024 19:07:29 -0000
@@ -100,6 +100,9 @@
 #include <machine/mpbiosvar.h>
 #include <machine/kcore.h>
 #include <machine/tss.h>
+#ifdef KASAN
+#include <machine/kasan.h>
+#endif
 
 #include <dev/isa/isareg.h>
 #include <dev/ic/i8042reg.h>
@@ -1422,6 +1425,9 @@ init_x86_64(paddr_t first_avail)
 	bios_memmap_t *bmp;
 	int x, ist;
 	uint64_t max_dm_size = ((uint64_t)512 * NUM_L4_SLOT_DIRECT) << 30;
+#ifdef KASAN
+	vaddr_t kasan_maxkvaddr;
+#endif
 
 	/*
 	 * locore0 mapped 3 pages for use before the pmap is initialized
@@ -1746,6 +1752,9 @@ init_x86_64(paddr_t first_avail)
 		}
 	}
 
+#ifdef KASAN
+	kasan_maxkvaddr =
+#endif
 	pmap_growkernel(VM_MIN_KERNEL_ADDRESS + 32 * 1024 * 1024);
 
 	pmap_kenter_pa(idt_vaddr, idt_paddr, PROT_READ | PROT_WRITE);
@@ -1799,6 +1808,11 @@ init_x86_64(paddr_t first_avail)
 	ddb_init();
 	if (boothowto & RB_KDB)
 		db_enter();
+#endif
+#ifdef KASAN
+	kasan_init();
+        kasan_enter_shad_multi((vaddr_t)VM_MIN_KERNEL_ADDRESS,
+	    kasan_maxkvaddr - VM_MIN_KERNEL_ADDRESS); /* XXX: doing it all */
 #endif
 }
 
Index: arch/amd64/amd64/pmap.c
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/pmap.c,v
diff -u -p -r1.169 pmap.c
--- arch/amd64/amd64/pmap.c	9 Jul 2024 19:11:06 -0000	1.169
+++ arch/amd64/amd64/pmap.c	14 Jul 2024 19:07:29 -0000
@@ -116,6 +116,9 @@
 #include <machine/i82489reg.h>
 #include <machine/i82489var.h>
 #endif
+#ifdef KASAN
+#include <machine/kasan.h>
+#endif
 
 #include "vmm.h"
 
@@ -3078,6 +3081,11 @@ pmap_growkernel(vaddr_t maxkvaddr)
 	}
 	pmap_maxkvaddr = maxkvaddr;
 	splx(s);
+
+#ifdef KASAN
+	kasan_enter_shad_multi((vaddr_t)VM_MIN_KERNEL_ADDRESS, 
+	    maxkvaddr - VM_MIN_KERNEL_ADDRESS);
+#endif
 
 	return maxkvaddr;
 }
Index: arch/amd64/conf/GENERIC.MP
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/GENERIC.MP,v
diff -u -p -r1.16 GENERIC.MP
--- arch/amd64/conf/GENERIC.MP	9 Feb 2021 14:06:19 -0000	1.16
+++ arch/amd64/conf/GENERIC.MP	14 Jul 2024 19:07:29 -0000
@@ -5,5 +5,5 @@ include "arch/amd64/conf/GENERIC"
 option	MULTIPROCESSOR
 #option	MP_LOCKDEBUG
 #option	WITNESS
-
+option KASAN
 cpu*		at mainbus?
Index: arch/amd64/conf/Makefile.amd64
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/Makefile.amd64,v
diff -u -p -r1.137 Makefile.amd64
--- arch/amd64/conf/Makefile.amd64	7 Jun 2024 05:17:34 -0000	1.137
+++ arch/amd64/conf/Makefile.amd64	14 Jul 2024 19:07:29 -0000
@@ -1,4 +1,4 @@
-#	$OpenBSD: Makefile.amd64,v 1.137 2024/06/07 05:17:34 deraadt Exp $
+#	$OpenBSD: Makefile.amd64,v 1.129 2023/01/01 01:34:33 jsg Exp $
 
 # For instructions on building kernels consult the config(8) and options(4)
 # manual pages.
@@ -53,7 +53,7 @@ INCLUDES=	-nostdinc -I$S -I${.OBJDIR} -I
 CPPFLAGS=	${INCLUDES} ${IDENT} ${PARAM} -D_KERNEL -MD -MP
 CWARNFLAGS=	-Werror -Wall -Wimplicit-function-declaration \
 		-Wno-pointer-sign \
-		-Wframe-larger-than=2047
+		-Wframe-larger-than=16382
 
 CMACHFLAGS=	-mcmodel=kernel -mno-red-zone -mno-sse2 -mno-sse -mno-3dnow \
 		-mno-mmx -msoft-float -fno-omit-frame-pointer
@@ -73,7 +73,7 @@ CMACHFLAGS+=	-mno-retpoline -fcf-protect
 .endif
 .else
 CMACHFLAGS+=	-mretpoline-external-thunk -fcf-protection=branch
-CMACHFLAGS+=	-fret-clean
+#CMACHFLAGS+=	-fret-clean
 .endif
 .if ${COMPILER_VERSION:Mclang}
 NO_INTEGR_AS=	-no-integrated-as
@@ -136,6 +136,12 @@ CFLAGS+=	-fsanitize=undefined
 CFLAGS+=	-fno-wrapv
 .endif
 
+KASAN_ENABLED = -fsanitize=kernel-address --param asan-globals=1 -mllvm -asan-instrumentation-with-call-threshold=0 -mllvm -asan-mapping-offset=0xdfff908000000000
+
+.if ${IDENT:M-DKASAN} && ${COMPILER_VERSION:Mclang}
+#CFLAGS+=${KASAN_ENABLED}
+.endif
+
 %LOAD
 
 # cc's -MD puts the source and output paths in the dependency file;
@@ -192,6 +198,18 @@ vers.o: ${SYSTEM_DEP:Ngap.o}
 .if ${SYSTEM_OBJ:Mkcov.o} && ${COMPILER_VERSION:Mclang}
 kcov.o: $S/dev/kcov.c
 	${NORMAL_C} -fno-sanitize-coverage=trace-pc,trace-cmp
+.endif
+
+# XXX: add subr_asan.o check
+.if ${SYSTEM_OBJ:Mkasan.o} && ${COMPILER_VERSION:Mclang}
+kasan.o: $S/arch/amd64/amd64/kasan.c
+	${NORMAL_C} -fno-sanitize=kernel-address
+subr_kasan.o: $S/kern/subr_kasan.c
+	${NORMAL_C} -fno-sanitize=kernel-address
+machdep.o: $S/arch/amd64/amd64/machdep.c
+	${NORMAL_C} -fno-sanitize=kernel-address
+init_main.o: $S/kern/init_main.c
+	${NORMAL_C} ${KASAN_ENABLED}
 .endif
 
 HARDFLOAT_CFLAGS= -msse -msse2
Index: arch/amd64/conf/files.amd64
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/files.amd64,v
diff -u -p -r1.109 files.amd64
--- arch/amd64/conf/files.amd64	8 Jul 2023 08:01:10 -0000	1.109
+++ arch/amd64/conf/files.amd64	14 Jul 2024 19:07:29 -0000
@@ -10,6 +10,7 @@ file	arch/amd64/amd64/gdt.c			multiproce
 file	arch/amd64/amd64/machdep.c
 file	arch/amd64/amd64/hibernate_machdep.c	hibernate
 file	arch/amd64/amd64/identcpu.c
+file	arch/amd64/amd64/kasan.c		kasan
 file	arch/amd64/amd64/tsc.c
 file	arch/amd64/amd64/via.c
 file	arch/amd64/amd64/locore.S
Index: arch/amd64/conf/ld.script
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/ld.script,v
diff -u -p -r1.19 ld.script
--- arch/amd64/conf/ld.script	7 Nov 2022 01:41:57 -0000	1.19
+++ arch/amd64/conf/ld.script	14 Jul 2024 19:07:29 -0000
@@ -85,6 +85,10 @@ SECTIONS
 	{
 		__rodata_start = ABSOLUTE(.);
 		*(.rodata .rodata.*)
+		. = ALIGN(64);
+		__CTOR_LIST__ = .;
+		*(.ctors)
+		__CTOR_END__ = .;
 		. = ALIGN(8);
 		__nofault_start = ABSOLUTE(.);
 		*(.nofault.*) *(.nofault)
Index: arch/amd64/include/kasan.h
===================================================================
RCS file: arch/amd64/include/kasan.h
diff -N arch/amd64/include/kasan.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ arch/amd64/include/kasan.h	14 Jul 2024 19:07:30 -0000
@@ -0,0 +1,10 @@
+/*    $OpenBSD$       */
+
+#ifndef _MACHINE_KASAN_H_
+#define _MACHINE_KASAN_H_
+
+void	kasan_init(void);
+void	kasan_ctors(void);
+void	kasan_enter_shad_multi(vaddr_t, size_t);
+
+#endif /* !_MACHINE_KASAN_H_ */
Index: arch/amd64/include/pmap.h
===================================================================
RCS file: /cvs/src/sys/arch/amd64/include/pmap.h,v
diff -u -p -r1.89 pmap.h
--- arch/amd64/include/pmap.h	9 Jul 2024 19:11:06 -0000	1.89
+++ arch/amd64/include/pmap.h	14 Jul 2024 19:07:30 -0000
@@ -145,11 +145,13 @@
 #define NUM_L4_SLOT_DIRECT	4
 #define L4_SLOT_DIRECT		(L4_SLOT_KERNBASE - NUM_L4_SLOT_DIRECT)
 #define L4_SLOT_EARLY		(L4_SLOT_DIRECT - 1)
+#define L4_SLOT_KASAN		(L4_SLOT_KERN + 1)
 
 #define PDIR_SLOT_KERN		L4_SLOT_KERN
 #define PDIR_SLOT_PTE		L4_SLOT_PTE
 #define PDIR_SLOT_DIRECT	L4_SLOT_DIRECT
 #define PDIR_SLOT_EARLY		L4_SLOT_EARLY
+#define PDIR_SLOT_KASAN		L4_SLOT_KASAN
 
 /*
  * the following defines give the virtual addresses of various MMU
Index: conf/files
===================================================================
RCS file: /cvs/src/sys/conf/files,v
diff -u -p -r1.734 files
--- conf/files	13 Jul 2024 13:20:44 -0000	1.734
+++ conf/files	14 Jul 2024 19:07:31 -0000
@@ -741,6 +741,7 @@ file kern/subr_evcount.c
 file kern/subr_extent.c
 file kern/subr_suspend.c		suspend
 file kern/subr_hibernate.c		hibernate
+file kern/subr_kasan.c			kasan
 file kern/subr_kubsan.c			kubsan
 file kern/subr_log.c
 file kern/subr_percpu.c
Index: kern/init_main.c
===================================================================
RCS file: /cvs/src/sys/kern/init_main.c,v
diff -u -p -r1.326 init_main.c
--- kern/init_main.c	2 Apr 2024 08:39:16 -0000	1.326
+++ kern/init_main.c	14 Jul 2024 19:07:34 -0000
@@ -74,6 +74,10 @@
 #include <sys/smr.h>
 #include <sys/evcount.h>
 
+#ifdef KASAN
+#include <sys/kasan.h>
+#endif
+
 #include <sys/syscallargs.h>
 
 #include <uvm/uvm_extern.h>
@@ -424,6 +428,9 @@ main(void *framep)
 		if (fork1(p, FORK_FORK, start_init, NULL, NULL, &initproc))
 			panic("fork init");
 		initprocess = initproc->p_p;
+#ifdef KASAN
+printf("DEBUG PARENT: kasan_in_init=%d\n", kasan_in_init);
+#endif
 	}
 
 	/*
@@ -561,6 +568,9 @@ static char *initpaths[] = {
 };
 
 void
+#ifdef KASAN
+__attribute__((no_sanitize("address")))
+#endif
 check_console(struct proc *p)
 {
 	struct nameidata nd;
@@ -582,6 +592,9 @@ check_console(struct proc *p)
  * The program is invoked with one argument containing the boot flags.
  */
 void
+#ifdef KASAN
+__attribute__((no_sanitize("address")))
+#endif
 start_init(void *arg)
 {
 	struct proc *p = arg;
@@ -600,6 +613,9 @@ start_init(void *arg)
 	/*
 	 * Now in process 1.
 	 */
+#ifdef KASAN
+	kasan_in_init = 1;
+#endif
 
 	/*
 	 * Wait for main() to tell us that it's safe to exec.
@@ -713,6 +729,9 @@ start_init(void *arg)
 		 */
 		if ((error = sys_execve(p, &args, retval)) == EJUSTRETURN) {
 			KERNEL_UNLOCK();
+#ifdef KASAN
+			kasan_in_init = 0;
+#endif
 			return;
 		}
 		if (error != ENOENT)
Index: kern/kern_malloc.c
===================================================================
RCS file: /cvs/src/sys/kern/kern_malloc.c,v
diff -u -p -r1.152 kern_malloc.c
--- kern/kern_malloc.c	26 Jun 2024 01:40:49 -0000	1.152
+++ kern/kern_malloc.c	14 Jul 2024 19:07:34 -0000
@@ -50,6 +50,11 @@
 #include <ddb/db_output.h>
 #endif
 
+#ifdef KASAN
+#include <machine/vmmvar.h>
+#include <sys/kasan.h>
+#endif
+
 static
 #ifndef SMALL_KERNEL
 __inline__
@@ -152,6 +157,11 @@ malloc(size_t size, int type, int flags)
 	int freshalloc;
 	char *savedtype;
 #endif
+#ifdef KASAN
+	size_t origsz = size;
+
+	kasan_add_redzone(&size);
+#endif
 #ifdef KMEMSTATS
 	struct kmemstats *ksp = &kmemstats[type];
 	int wake;
@@ -343,8 +353,17 @@ out:
 #endif
 	mtx_leave(&malloc_mtx);
 
+#ifdef KASAN
+	kasan_alloc((vaddr_t)va, origsz, size);
+#endif
 	if ((flags & M_ZERO) && va != NULL)
-		memset(va, 0, size);
+		memset(va, 0,
+#ifdef KASAN
+		    origsz
+#else
+		    size
+#endif
+		);
 
 	TRACEPOINT(uvm, malloc, type, va, size, flags);
 
@@ -365,6 +384,10 @@ free(void *addr, int type, size_t freeds
 #ifdef DIAGNOSTIC
 	long alloc;
 #endif
+#ifdef KASAN
+	if (freedsize != 0)
+		kasan_add_redzone(&freedsize);
+#endif
 #ifdef KMEMSTATS
 	struct kmemstats *ksp = &kmemstats[type];
 	int wake;
@@ -481,6 +504,9 @@ free(void *addr, int type, size_t freeds
 #endif
 	XSIMPLEQ_INSERT_TAIL(&kbp->kb_freelist, freep, kf_flist);
 	mtx_leave(&malloc_mtx);
+#ifdef KASAN
+	kasan_free((vaddr_t)addr, size);
+#endif
 #ifdef KMEMSTATS
 	if (wake)
 		wakeup(ksp);
Index: kern/subr_kasan.c
===================================================================
RCS file: kern/subr_kasan.c
diff -N kern/subr_kasan.c
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ kern/subr_kasan.c	14 Jul 2024 19:07:34 -0000
@@ -0,0 +1,563 @@
+/*	$OpenBSD$	*/
+
+#include <sys/param.h>
+#include <sys/proc.h>
+#include <sys/tree.h>
+#include <sys/types.h>
+#include <sys/systm.h>
+#include <sys/user.h>
+
+#include <uvm/uvm_extern.h>
+
+#include <machine/kasan.h>
+#include <machine/cpu.h>
+#include <machine/pmap.h>
+#include <machine/segments.h>
+#include <machine/vmmvar.h>
+
+#include <ddb/db_output.h>
+
+#include <sys/kasan.h>
+
+#define __RET_ADDR	(vaddr_t)__builtin_return_address(0)
+
+#define ADDR_CROSSES_SCALE_BOUNDARY(addr, size) 		\
+	(addr >> KASAN_SHADOW_SCALE_SHIFT) !=			\
+	    ((addr + size - 1) >> KASAN_SHADOW_SCALE_SHIFT)
+
+void kasan_init(void);
+int pmap_get_physpage(vaddr_t, int, paddr_t *); // XXX
+
+static int kasan_enabled = 0;
+static paddr_t kasan_zero = 0;
+int kasan_in_init = 0;
+
+static int
+kasan_unsupported(vaddr_t addr)
+{
+	return (addr >= VM_MAX_KERNEL_ADDRESS ||
+	    addr < VM_MIN_KERNEL_ADDRESS);
+}
+
+int
+kasan_enter_shad(vaddr_t sva, paddr_t pa)
+{
+	uint64_t l4idx, l3idx, l2idx, l1idx;
+	pd_entry_t *pd, npte;
+	paddr_t npa;
+	struct pmap *pmap = pmap_kernel();
+
+	l4idx = (sva & L4_MASK) >> L4_SHIFT; /* PML4E idx */
+	l3idx = (sva & L3_MASK) >> L3_SHIFT; /* PDPTE idx */
+	l2idx = (sva & L2_MASK) >> L2_SHIFT; /* PDE idx */
+	l1idx = (sva & L1_MASK) >> L1_SHIFT; /* PTE idx */
+
+	/* Start at PML4 / top level */
+	pd = (pd_entry_t *)pmap->pm_pdir;
+
+	if (pd == NULL)
+		return ENOMEM;
+
+	/* npa = physaddr of PDPT */
+	npa = pd[l4idx] & PMAP_PA_MASK & PG_FRAME;
+
+	/* Valid PML4e for the 512GB region containing sva? */
+	if (!npa) {
+		/* No valid PML4e - allocate PDPT page and set PML4e */
+		pmap_get_physpage(sva, 3, &npa);
+
+		/*
+		 * Higher levels get full perms; specific permissions are
+		 * entered at the lowest level.
+		 */
+		pd[l4idx] = (npa | PG_KW | pg_nx | PG_V);
+	}
+
+	pd = (pd_entry_t *)PMAP_DIRECT_MAP(npa);
+	if (pd == NULL)
+		panic("%s: can't locate PDPT @ pa=0x%llx", __func__,
+		    (uint64_t)npa);
+
+	/* npa = physaddr of PD page */
+	npa = pd[l3idx] & PMAP_PA_MASK & PG_FRAME;
+
+	/* Valid PDPTe for the 1GB region containing sva? */
+	if (!npa) {
+		/* No valid PDPTe - allocate PD page and set PDPTe */
+		pmap_get_physpage(sva, 2, &npa);
+
+		/*
+		 * Higher levels get full perms; specific permissions are
+		 * entered at the lowest level.
+		 */
+		pd[l3idx] = (npa | PG_KW | pg_nx | PG_V);
+	}
+
+	pd = (pd_entry_t *)PMAP_DIRECT_MAP(npa);
+	if (pd == NULL)
+		panic("%s: can't locate PD page @ pa=0x%llx", __func__,
+		    (uint64_t)npa);
+
+	/* npa = physaddr of PT page */
+	npa = pd[l2idx] & PMAP_PA_MASK & PG_FRAME;
+
+	/* Valid PDE for the 2MB region containing sva? */
+	if (!npa) {
+		/* No valid PDE - allocate PT page and set PDE */
+		pmap_get_physpage(sva, 1, &npa);
+
+		/*
+		 * Higher level get full perms; specific permissions are
+		 * entered at the lowest level.
+		 */
+		pd[l2idx] = (npa | PG_KW | pg_g_kern | pg_nx | PG_V);
+	}
+
+	pd = (pd_entry_t *)PMAP_DIRECT_MAP(npa);
+	if (pd == NULL)
+		panic("%s: can't locate PT page @ pa=0x%llx", __func__,
+		    (uint64_t)npa);
+
+	npte = pa | PG_KW | pg_nx | PG_V;
+
+	if (pd[l1idx] == 0) {
+		pmap->pm_stats.resident_count++;
+	} else {
+		/* XXX flush ept */
+	}
+
+	pd[l1idx] = npte;
+
+	return 0;
+}
+
+void
+kasan_enter_shad_multi(vaddr_t va, size_t sz)
+{
+	size_t ssz, spgs, i;
+	vaddr_t sva;
+
+	sva = (vaddr_t)kasan_addr_to_shad(va);
+	ssz = (sz + KASAN_SHADOW_SCALE_SIZE - 1) / KASAN_SHADOW_SCALE_SIZE;
+	sva = (sva / PAGE_SIZE) * PAGE_SIZE;
+	spgs = (ssz + PAGE_SIZE - 1) / PAGE_SIZE;
+
+printf("early start: 0x%llx\n", VA_SIGN_NEG((L4_SLOT_EARLY * NBPD_L4)));
+printf("shadow start: 0x%lx\n", KASAN_SHADOW_START);
+printf("shadow end: 0x%lx\n", KASAN_SHADOW_END);
+printf("mapped 0x%lx to 0x%lx\n", sva, sva + ssz);
+	for (i = 0; i < spgs; i++)
+{
+		if (kasan_enter_shad(sva + i * PAGE_SIZE, kasan_zero))
+			panic("failed to create kasa page at 0x%lx", sva +
+			    i * PAGE_SIZE);
+//printf("mapped 0x%lx\n", sva + i * PAGE_SIZE);
+}
+
+}
+
+vaddr_t		pmap_steal_memory(vsize_t, vaddr_t *, vaddr_t *);
+/*
+ * Create the shadow mapping. We don't create the 'User' area, because we
+ * exclude it from the monitoring. The 'Main' area is created dynamically
+ * in pmap_growkernel.
+ */
+void
+kasan_init(void)
+{
+	vaddr_t zva;
+
+	if (kasan_zero == 0) {
+printf("allocing kasan_zero\n");
+		zva = pmap_steal_memory(PAGE_SIZE, NULL, NULL);
+                kasan_zero = PMAP_DIRECT_UNMAP(zva);
+		pmap_get_physpage(zva, 1, &kasan_zero);
+		__builtin_memset((char *)zva, 0xFF, PAGE_SIZE);
+	}
+
+printf("stack: 0x%lx\n", (vaddr_t)proc0.p_addr + USPACE - 16);
+
+	/* map stack memory */
+	kasan_enter_shad_multi((vaddr_t)proc0.p_addr + USPACE - 16,
+	    1024 * 1024 * 2);
+
+	kasan_enter_shad_multi(VM_MIN_KERNEL_ADDRESS,
+	    VM_MAX_KERNEL_ADDRESS - VM_MIN_KERNEL_ADDRESS);
+	kasan_enabled = 1;
+
+	/* Call the ASAN constructors. */
+	kasan_ctors();
+}
+
+static void
+kasan_report(vaddr_t addr, size_t size, int op, vaddr_t rip)
+{
+	printf("KASAN: unregistered access at 0x%lx: "
+	    "%s of %lu byte%s from 0x%lx\n", rip,
+	    (op ? "write" : "read"), size, (size > 1 ? "s" : ""), addr);
+}
+
+static void
+kasan_shadow_fill(vaddr_t addr, size_t size, uint8_t val)
+{
+	char *shad;
+
+	if (!kasan_enabled || kasan_in_init)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	KASSERT(addr % KASAN_SHADOW_SCALE_SIZE == 0);
+	KASSERT(size % KASAN_SHADOW_SCALE_SIZE == 0);
+
+	shad = kasan_addr_to_shad(addr);
+	size = size >> KASAN_SHADOW_SCALE_SHIFT;
+
+	__builtin_memset(shad, val, size);
+}
+
+static inline void
+kasan_shadow_1byte_markvalid(vaddr_t addr)
+{
+	char *byte = kasan_addr_to_shad(addr);
+	char last = (addr & KASAN_SHADOW_MASK) + 1;
+
+	*byte = last;
+}
+
+void
+kasan_add_redzone(size_t *size)
+{
+	*size = roundup(*size, KASAN_SHADOW_SCALE_SIZE);
+	*size += KASAN_SHADOW_SCALE_SIZE;
+}
+
+struct vm_page *pmap_find_ptp(struct pmap *, vaddr_t, paddr_t, int);
+
+static void
+kasan_markmem(vaddr_t addr, size_t size, int valid)
+{
+	struct vm_page *vm;
+	size_t i;
+
+	KASSERT(addr % KASAN_SHADOW_SCALE_SIZE == 0);
+
+	// XXX: PHYS_TO_VM_PAGE might also work
+	if ((vm = pmap_find_ptp(pmap_kernel(), addr, kasan_zero, 1)) == NULL) {
+		//		printf("found pmap pa ptp kasan_zero thing\n");
+	} else {
+		//		panic("no pmap pa ptp kasan_zero thing\n");
+	}
+
+	if (valid) {
+		for (i = 0; i < size; i++)
+			kasan_shadow_1byte_markvalid(addr + i);
+	} else {
+		KASSERT(size % KASAN_SHADOW_SCALE_SIZE == 0);
+		kasan_shadow_fill(addr, size, KASAN_MEMORY_REDZONE);
+	}
+}
+
+void
+kasan_alloc(vaddr_t addr, size_t size, size_t sz_with_redz)
+{
+	if (!kasan_enabled || kasan_in_init)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		panic("malloc 0x%lx outside of VM_KERNEL_ADDRESS range", addr);
+	printf("kasan_alloc 0x%lx %lu %lu\n", addr, sz_with_redz, size);
+	kasan_markmem(addr, sz_with_redz, 0);
+	kasan_markmem(addr, size, 1);
+}
+
+void
+kasan_free(vaddr_t addr, size_t sz_with_redz)
+{
+	if (!kasan_enabled || kasan_in_init)
+		return;
+	if (sz_with_redz == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	kasan_markmem(addr, sz_with_redz, 1);
+}
+
+static inline int
+kasan_shadow_1byte_isvalid(vaddr_t addr)
+{
+	char *byte = kasan_addr_to_shad(addr);
+	char last = (addr & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_2byte_isvalid(vaddr_t addr)
+{
+	char *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 2)) {
+		return (kasan_shadow_1byte_isvalid(addr) &&
+		    kasan_shadow_1byte_isvalid(addr + 1));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 1) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_4byte_isvalid(vaddr_t addr)
+{
+	char *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 4)) {
+		return (kasan_shadow_2byte_isvalid(addr) &&
+		    kasan_shadow_2byte_isvalid(addr + 2));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 3) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_8byte_isvalid(vaddr_t addr)
+{
+	int8_t *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 8)) {
+		return (kasan_shadow_4byte_isvalid(addr) &&
+		    kasan_shadow_4byte_isvalid(addr + 4));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 7) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_Nbyte_isvalid(vaddr_t addr, size_t size)
+{
+	size_t i;
+
+	for (i = 0; i < size; i++) {
+		if (!kasan_shadow_1byte_isvalid(addr + i))
+			return 0;
+	}
+
+	return 1;
+}
+
+static size_t valid_access = 0;
+static inline void
+kasan_shadow_check(vaddr_t addr, size_t size, int op, vaddr_t retaddr)
+{
+	int valid;
+
+	if (!kasan_enabled || kasan_in_init)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	if (__builtin_constant_p(size)) {
+		switch (size) {
+		case 1:
+			valid = kasan_shadow_1byte_isvalid(addr);
+			break;
+		case 2:
+			valid = kasan_shadow_2byte_isvalid(addr);
+			break;
+		case 4:
+			valid = kasan_shadow_4byte_isvalid(addr);
+			break;
+		case 8:
+			valid = kasan_shadow_8byte_isvalid(addr);
+			break;
+		default:
+			valid = kasan_shadow_Nbyte_isvalid(addr, size);
+			break;
+		}
+	} else {
+		valid = kasan_shadow_Nbyte_isvalid(addr, size);
+	}
+
+	if (!valid) {
+		printf("%zu valid accesses\n", valid_access);
+		kasan_report(addr, size, op, retaddr);
+#ifdef DDB
+		db_stack_dump();
+		panic("Caught invalid memory access at %lx size %lu op %d",
+		    addr, size, op);
+#endif
+	} else
+		valid_access++;
+}
+
+void *
+kasan_memcpy(void *dst, const void *src, size_t len)
+{
+	kasan_shadow_check((vaddr_t)src, len, 0, __RET_ADDR);
+	kasan_shadow_check((vaddr_t)dst, len, 1, __RET_ADDR);
+	return __builtin_memcpy(dst, src, len);
+}
+
+int
+kasan_memcmp(const void *b1, const void *b2, size_t len)
+{
+	kasan_shadow_check((vaddr_t)b1, len, 0, __RET_ADDR);
+	kasan_shadow_check((vaddr_t)b2, len, 0, __RET_ADDR);
+	return __builtin_memcmp(b1, b2, len);
+}
+
+void *
+kasan_memset(void *b, int c, size_t len)
+{
+	kasan_shadow_check((vaddr_t)b, len, 1, __RET_ADDR);
+	return __builtin_memset(b, c, len);
+}
+
+static void
+kasan_register_global(struct __asan_global *global)
+{
+	size_t aligned_size = roundup(global->size, KASAN_SHADOW_SCALE_SIZE);
+
+	/* Poison the redzone following the var. */
+	kasan_shadow_fill((vaddr_t)((uintptr_t)global->beg + aligned_size),
+	    global->size_with_redzone - aligned_size, KASAN_GLOBAL_REDZONE);
+}
+
+void
+__asan_register_globals(struct __asan_global *globals, size_t size)
+{
+printf("%s\n", __func__);
+	size_t i;
+	for (i = 0; i < size; i++) {
+		kasan_register_global(&globals[i]);
+	}
+}
+
+void
+__asan_unregister_globals(struct __asan_global *globals, size_t size)
+{
+printf("%s\n", __func__);
+}
+
+#define ASAN_LOAD_STORE(size)					\
+	void __asan_load##size(unsigned long);			\
+	void __asan_load##size(unsigned long addr)		\
+	{							\
+		kasan_shadow_check(addr, size, 0, __RET_ADDR);\
+	} 							\
+	void __asan_load##size##_noabort(unsigned long);	\
+	void __asan_load##size##_noabort(unsigned long addr)	\
+	{							\
+		kasan_shadow_check(addr, size, 0, __RET_ADDR);\
+	}							\
+	void __asan_store##size(unsigned long);			\
+	void __asan_store##size(unsigned long addr)		\
+	{							\
+		kasan_shadow_check(addr, size, 1, __RET_ADDR);\
+	}							\
+	void __asan_store##size##_noabort(unsigned long);	\
+	void __asan_store##size##_noabort(unsigned long addr)	\
+	{							\
+		kasan_shadow_check(addr, size, 1, __RET_ADDR);\
+	}
+
+ASAN_LOAD_STORE(1);
+ASAN_LOAD_STORE(2);
+ASAN_LOAD_STORE(4);
+ASAN_LOAD_STORE(8);
+ASAN_LOAD_STORE(16);
+
+void
+__asan_loadN(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 0, __RET_ADDR);
+}
+
+void
+__asan_loadN_noabort(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 0, __RET_ADDR);
+}
+
+void
+__asan_storeN(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 1, __RET_ADDR);
+}
+
+void
+__asan_storeN_noabort(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 1, __RET_ADDR);
+}
+
+void
+__asan_handle_no_return(void)
+{
+printf("%s\n", __func__);
+	/* nothing */
+}
+
+void
+__asan_poison_stack_memory(const void *addr, size_t size)
+{
+printf("%s\n", __func__);
+	vaddr_t va = (vaddr_t)addr;
+	KASSERT(va % KASAN_SHADOW_SCALE_SIZE == 0);
+	kasan_shadow_fill(va, size, KASAN_USE_AFTER_SCOPE);
+}
+
+void
+__asan_unpoison_stack_memory(const void *addr, size_t size)
+{
+printf("%s\n", __func__);
+	vaddr_t va = (vaddr_t)addr;
+	KASSERT(va % KASAN_SHADOW_SCALE_SIZE == 0);
+	kasan_shadow_fill(va, size, 0);
+}
+
+void
+__asan_alloca_poison(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	panic("%s: impossible!", __func__);
+}
+
+void
+__asan_allocas_unpoison(const void *stack_top, const void *stack_bottom)
+{
+printf("%s\n", __func__);
+	panic("%s: impossible!", __func__);
+}
+
+#define ASAN_SET_SHADOW(byte) \
+	void __asan_set_shadow_##byte(void *, size_t);			\
+	void __asan_set_shadow_##byte(void *addr, size_t size)		\
+	{								\
+		__builtin_memset((void *)addr, 0x##byte, size);		\
+	}
+
+ASAN_SET_SHADOW(00);
+ASAN_SET_SHADOW(f1);
+ASAN_SET_SHADOW(f2);
+ASAN_SET_SHADOW(f3);
+ASAN_SET_SHADOW(f5);
+ASAN_SET_SHADOW(f8);
Index: sys/kasan.h
===================================================================
RCS file: sys/kasan.h
diff -N sys/kasan.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ sys/kasan.h	14 Jul 2024 19:07:34 -0000
@@ -0,0 +1,87 @@
+/*	$OpenBSD$	*/
+
+#ifndef _SYS_KASAN_H_
+#define _SYS_KASAN_H_
+
+#define KASAN_SHADOW_SCALE_SHIFT	3
+#define KASAN_SHADOW_SCALE_SIZE		(1UL << KASAN_SHADOW_SCALE_SHIFT)
+#define KASAN_SHADOW_MASK		(KASAN_SHADOW_SCALE_SIZE - 1)
+
+#define KASAN_SHADOW_SIZE	((0xffffffffffffffff - VM_MIN_KERNEL_ADDRESS) >> 3)
+#define KASAN_SHADOW_START	(0xffff808000000000)
+#if 0
+#define KASAN_SHADOW_START	(VA_SIGN_NEG((L4_SLOT_KASAN * NBPD_L4)))
+#endif
+#define KASAN_SHADOW_END	(KASAN_SHADOW_START + KASAN_SHADOW_SIZE)
+
+/* Our redzone values. */
+#define KASAN_GLOBAL_REDZONE	0xFA
+#define KASAN_MEMORY_REDZONE	0xFB
+
+/* Stack redzone shadow values. Part of the compiler ABI. */
+#define KASAN_STACK_LEFT	0xF1
+#define KASAN_STACK_MID		0xF2
+#define KASAN_STACK_RIGHT	0xF3
+#define KASAN_STACK_PARTIAL	0xF4
+#define KASAN_USE_AFTER_SCOPE	0xF8
+
+extern int kasan_in_init;
+
+inline char *
+kasan_addr_to_shad(vaddr_t va)
+{
+	return (char *)(KASAN_SHADOW_START +
+	    ((va - VM_MIN_KERNEL_ADDRESS) >> KASAN_SHADOW_SCALE_SHIFT));
+}
+
+void	 kasan_add_redzone(size_t *);
+void	 kasan_alloc(vaddr_t, size_t, size_t);
+void	 kasan_free(vaddr_t, size_t);
+
+struct __asan_global;
+
+void __asan_register_globals(struct __asan_global *, size_t);
+void __asan_unregister_globals(struct __asan_global *, size_t);
+
+void __asan_loadN(unsigned long, size_t);
+void __asan_loadN_noabort(unsigned long, size_t);
+void __asan_storeN(unsigned long, size_t);
+void __asan_storeN_noabort(unsigned long, size_t);
+void __asan_handle_no_return(void);
+void __asan_poison_stack_memory(const void *, size_t);
+void __asan_unpoison_stack_memory(const void *, size_t);
+void __asan_alloca_poison(unsigned long, size_t);
+void __asan_allocas_unpoison(const void *, const void *);
+
+#if defined(__clang__) && (__clang_major__ - 0 >= 6)
+#define ASAN_ABI_VERSION	8
+#elif __GNUC_PREREQ__(7, 1) && !defined(__clang__)
+#define ASAN_ABI_VERSION	8
+#elif __GNUC_PREREQ__(6, 1) && !defined(__clang__)
+#define ASAN_ABI_VERSION	6
+#else
+#error "Unsupported compiler version"
+#endif
+
+/*
+ * Part of the compiler ABI.
+ */
+struct __asan_global_source_location {
+	const char *filename;
+	int line_no;
+	int column_no;
+};
+struct __asan_global {
+	const void *beg;		/* address of the global variable */
+	size_t size;			/* size of the global variable */
+	size_t size_with_redzone;	/* size with the redzone */
+	const void *name;		/* name of the variable */
+	const void *module_name;	/* name of the module where the var is declared */
+	unsigned long has_dynamic_init;	/* the var has dyn initializer (c++) */
+	struct __asan_global_source_location *location;
+#if ASAN_ABI_VERSION >= 7
+	uintptr_t odr_indicator;	/* the address of the ODR indicator symbol */
+#endif
+};
+
+#endif /* !_SYS_KASAN_H_ */
Index: sys/systm.h
===================================================================
RCS file: /cvs/src/sys/sys/systm.h,v
diff -u -p -r1.171 systm.h
--- sys/systm.h	28 May 2024 12:50:23 -0000	1.171
+++ sys/systm.h	14 Jul 2024 19:07:34 -0000
@@ -387,10 +387,20 @@ extern int (*mountroot)(void);
 
 #include <lib/libkern/libkern.h>
 
+#ifdef KASAN
+void	*kasan_memset(void *, int, size_t);
+int	kasan_memcmp(const void *, const void *, size_t);
+void	*kasan_memcpy(void *, const void *, size_t);
+#define bzero(b, n)		kasan_memset((b), 0, (n))
+#define memcmp(b1, b2, n)	kasan_memcmp((b1), (b2), (n))
+#define memcpy(d, s, n)		kasan_memcpy((d), (s), (n))
+#define memset(b, c, n)		kasan_memset((b), (c), (n))
+#else
 #define bzero(b, n)		__builtin_bzero((b), (n))
 #define memcmp(b1, b2, n)	__builtin_memcmp((b1), (b2), (n))
 #define memcpy(d, s, n)		__builtin_memcpy((d), (s), (n))
 #define memset(b, c, n)		__builtin_memset((b), (c), (n))
+#endif
 #if (defined(__GNUC__) && __GNUC__ >= 4)
 #define memmove(d, s, n)	__builtin_memmove((d), (s), (n))
 #endif
Index: uvm/uvm_km.c
===================================================================
RCS file: /cvs/src/sys/uvm/uvm_km.c,v
diff -u -p -r1.152 uvm_km.c
--- uvm/uvm_km.c	27 Mar 2024 15:41:40 -0000	1.152
+++ uvm/uvm_km.c	14 Jul 2024 19:07:34 -0000
@@ -134,6 +134,10 @@
 #include <sys/proc.h>
 #include <sys/kthread.h>
 #include <uvm/uvm.h>
+#ifdef KASAN
+#include <machine/kasan.h>
+#include <sys/kasan.h>
+#endif
 
 /*
  * global data structures
@@ -773,6 +777,12 @@ km_alloc(size_t sz, const struct kmem_va
 	if (kv->kv_singlepage || kp->kp_maxseg == 1) {
 		TAILQ_FOREACH(pg, &pgl, pageq) {
 			va = pmap_map_direct(pg);
+#ifdef KASAN
+/* XXX: how to handle direct map?
+			kasan_enter_shad_multi(va, PAGE_SIZE);
+			kasan_alloc(va, (kp->kp_zero) ? PAGE_SIZE : 0, PAGE_SIZE);
+*/
+#endif
 			if (pg == TAILQ_FIRST(&pgl))
 				sva = va;
 		}
@@ -844,6 +854,10 @@ try_map:
 			pmap_kenter_pa(va, VM_PAGE_TO_PHYS(pg), prot);
 		va += PAGE_SIZE;
 	}
+#ifdef KASAN
+	kasan_enter_shad_multi(sva, sz);
+	kasan_alloc(sva, (kp->kp_zero) ? sz : 0 , sz);
+#endif
 	pmap_update(pmap_kernel());
 	return ((void *)sva);
 }
