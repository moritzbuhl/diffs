Index: arch/amd64/amd64/kasan.c
===================================================================
RCS file: arch/amd64/amd64/kasan.c
diff -N arch/amd64/amd64/kasan.c
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ arch/amd64/amd64/kasan.c	28 Apr 2023 08:35:01 -0000
@@ -0,0 +1,35 @@
+/*	$OpenBSD$	*/
+
+#include <sys/param.h>
+#include <sys/proc.h>
+#include <sys/systm.h>
+
+#include <uvm/uvm_extern.h>
+
+#include <machine/cpu.h>
+#include <machine/pmap.h>
+#include <machine/segments.h>
+#include <machine/vmmvar.h>
+
+#include <sys/kasan.h>
+
+void
+kasan_ctors(void)
+{
+	extern uint64_t __CTOR_LIST__, __CTOR_END__;
+	size_t nentries, i;
+	uint64_t *ptr;
+
+	nentries = ((size_t)&__CTOR_END__ - (size_t)&__CTOR_LIST__) /
+	    sizeof(uintptr_t);
+
+	ptr = &__CTOR_LIST__;
+	for (i = 0; i < nentries; i++) {
+		void (*func)(void);
+
+		func = (void *)(*ptr);
+		(*func)();
+
+		ptr++;
+	}
+}
Index: arch/amd64/amd64/machdep.c
===================================================================
RCS file: /cvs/src/sys/arch/amd64/amd64/machdep.c,v
retrieving revision 1.284
diff -u -p -r1.284 machdep.c
--- arch/amd64/amd64/machdep.c	29 Nov 2022 21:41:39 -0000	1.284
+++ arch/amd64/amd64/machdep.c	28 Apr 2023 08:21:56 -0000
@@ -100,6 +100,7 @@
 #include <machine/mpbiosvar.h>
 #include <machine/kcore.h>
 #include <machine/tss.h>
+#include <machine/kasan.h>
 
 #include <dev/isa/isareg.h>
 #include <dev/ic/i8042reg.h>
@@ -1356,6 +1357,9 @@ init_x86_64(paddr_t first_avail)
 	bios_memmap_t *bmp;
 	int x, ist;
 	uint64_t max_dm_size = ((uint64_t)512 * NUM_L4_SLOT_DIRECT) << 30;
+#ifdef KASAN
+	vaddr_t kasan_maxkvaddr;
+#endif
 
 	/*
 	 * locore0 mapped 3 pages for use before the pmap is initialized
@@ -1679,6 +1683,9 @@ init_x86_64(paddr_t first_avail)
 		}
 	}
 
+#ifdef KASAN
+	kasan_maxkvaddr =
+#endif
 	pmap_growkernel(VM_MIN_KERNEL_ADDRESS + 32 * 1024 * 1024);
 
 	pmap_kenter_pa(idt_vaddr, idt_paddr, PROT_READ | PROT_WRITE);
@@ -1735,6 +1742,13 @@ init_x86_64(paddr_t first_avail)
 	ddb_init();
 	if (boothowto & RB_KDB)
 		db_enter();
+#endif
+#ifdef KASAN
+/*
+	kasan_init();
+        kasan_enter_shad_multi((vaddr_t)VM_MIN_KERNEL_ADDRESS,
+            VM_MIN_KERNEL_ADDRESS - kasan_maxkvaddr);
+*/
 #endif
 }
 
Index: arch/amd64/conf/Makefile.amd64
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/Makefile.amd64,v
retrieving revision 1.132
diff -u -p -r1.132 Makefile.amd64
--- arch/amd64/conf/Makefile.amd64	21 Apr 2023 13:24:20 -0000	1.132
+++ arch/amd64/conf/Makefile.amd64	27 Apr 2023 08:34:03 -0000
@@ -1,4 +1,4 @@
-#	$OpenBSD: Makefile.amd64,v 1.132 2023/04/21 13:24:20 bluhm Exp $
+#	$OpenBSD: Makefile.amd64,v 1.129 2023/01/01 01:34:33 jsg Exp $
 
 # For instructions on building kernels consult the config(8) and options(4)
 # manual pages.
@@ -53,7 +53,7 @@ INCLUDES=	-nostdinc -I$S -I${.OBJDIR} -I
 CPPFLAGS=	${INCLUDES} ${IDENT} ${PARAM} -D_KERNEL -MD -MP
 CWARNFLAGS=	-Werror -Wall -Wimplicit-function-declaration \
 		-Wno-pointer-sign \
-		-Wframe-larger-than=2047
+		-Wframe-larger-than=16382
 
 CMACHFLAGS=	-mcmodel=kernel -mno-red-zone -mno-sse2 -mno-sse -mno-3dnow \
 		-mno-mmx -msoft-float -fno-omit-frame-pointer
@@ -138,6 +138,12 @@ CFLAGS+=	-fsanitize=undefined
 CFLAGS+=	-fno-wrapv
 .endif
 
+KASAN_ENABLED = -fsanitize=kernel-address --param asan-globals=1 -mllvm -asan-instrumentation-with-call-threshold=0
+
+.if ${IDENT:M-DKASAN} && ${COMPILER_VERSION:Mclang}
+#CFLAGS+=${KASAN_ENABLED}
+.endif
+
 %LOAD
 
 # cc's -MD puts the source and output paths in the dependency file;
@@ -194,6 +200,18 @@ vers.o: ${SYSTEM_DEP:Ngap.o}
 .if ${SYSTEM_OBJ:Mkcov.o} && ${COMPILER_VERSION:Mclang}
 kcov.o: $S/dev/kcov.c
 	${NORMAL_C} -fno-sanitize-coverage=trace-pc,trace-cmp
+.endif
+
+# XXX: add subr_asan.o check
+.if ${SYSTEM_OBJ:Mkasan.o} && ${COMPILER_VERSION:Mclang}
+kasan.o: $S/arch/amd64/amd64/kasan.c
+	${NORMAL_C} -fno-sanitize=kernel-address
+subr_kasan.o: $S/kern/subr_kasan.c
+	${NORMAL_C} -fno-sanitize=kernel-address
+machdep.o: $S/arch/amd64/amd64/machdep.c
+	${NORMAL_C} -fno-sanitize=kernel-address
+init_main.o: $S/kern/init_main.c
+	${NORMAL_C} ${KASAN_ENABLED}
 .endif
 
 HARDFLOAT_CFLAGS= -msse -msse2
Index: arch/amd64/conf/files.amd64
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/files.amd64,v
retrieving revision 1.108
diff -u -p -r1.108 files.amd64
--- arch/amd64/conf/files.amd64	26 Apr 2023 15:11:21 -0000	1.108
+++ arch/amd64/conf/files.amd64	27 Apr 2023 08:33:57 -0000
@@ -10,6 +10,7 @@ file	arch/amd64/amd64/gdt.c			multiproce
 file	arch/amd64/amd64/machdep.c
 file	arch/amd64/amd64/hibernate_machdep.c	hibernate
 file	arch/amd64/amd64/identcpu.c
+file	arch/amd64/amd64/kasan.c		kasan
 file	arch/amd64/amd64/tsc.c
 file	arch/amd64/amd64/via.c
 file	arch/amd64/amd64/locore.S
Index: arch/amd64/conf/ld.script
===================================================================
RCS file: /cvs/src/sys/arch/amd64/conf/ld.script,v
retrieving revision 1.19
diff -u -p -r1.19 ld.script
--- arch/amd64/conf/ld.script	7 Nov 2022 01:41:57 -0000	1.19
+++ arch/amd64/conf/ld.script	27 Apr 2023 08:33:57 -0000
@@ -85,6 +85,10 @@ SECTIONS
 	{
 		__rodata_start = ABSOLUTE(.);
 		*(.rodata .rodata.*)
+		. = ALIGN(64);
+		__CTOR_LIST__ = .;
+		*(.ctors)
+		__CTOR_END__ = .;
 		. = ALIGN(8);
 		__nofault_start = ABSOLUTE(.);
 		*(.nofault.*) *(.nofault)
Index: arch/amd64/include/kasan.h
===================================================================
RCS file: arch/amd64/include/kasan.h
diff -N arch/amd64/include/kasan.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ arch/amd64/include/kasan.h	28 Apr 2023 08:13:40 -0000
@@ -0,0 +1,10 @@
+/*	$OpenBSD$	*/
+
+#ifndef _MACHINE_KASAN_H_
+#define _MACHINE_KASAN_H_
+
+void	kasan_init(void);
+void	kasan_ctors(void);
+void	kasan_enter_shad_multi(vaddr_t, size_t);
+
+#endif /* !_MACHINE_KASAN_H_ */
Index: arch/amd64/include/pmap.h
===================================================================
RCS file: /cvs/src/sys/arch/amd64/include/pmap.h,v
retrieving revision 1.86
diff -u -p -r1.86 pmap.h
--- arch/amd64/include/pmap.h	13 Apr 2023 15:23:21 -0000	1.86
+++ arch/amd64/include/pmap.h	27 Apr 2023 08:34:00 -0000
@@ -145,11 +145,13 @@
 #define NUM_L4_SLOT_DIRECT	4
 #define L4_SLOT_DIRECT		(L4_SLOT_KERNBASE - NUM_L4_SLOT_DIRECT)
 #define L4_SLOT_EARLY		(L4_SLOT_DIRECT - 1)
+#define L4_SLOT_KASAN		(L4_SLOT_DIRECT - 2)
 
 #define PDIR_SLOT_KERN		L4_SLOT_KERN
 #define PDIR_SLOT_PTE		L4_SLOT_PTE
 #define PDIR_SLOT_DIRECT	L4_SLOT_DIRECT
 #define PDIR_SLOT_EARLY		L4_SLOT_EARLY
+#define PDIR_SLOT_KASAN		L4_SLOT_KASAN
 
 /*
  * the following defines give the virtual addresses of various MMU
Index: conf/files
===================================================================
RCS file: /cvs/src/sys/conf/files,v
retrieving revision 1.724
diff -u -p -r1.724 files
--- conf/files	23 Apr 2023 00:20:26 -0000	1.724
+++ conf/files	27 Apr 2023 08:34:00 -0000
@@ -736,6 +736,7 @@ file kern/subr_evcount.c
 file kern/subr_extent.c
 file kern/subr_suspend.c		suspend
 file kern/subr_hibernate.c		hibernate
+file kern/subr_kasan.c			kasan
 file kern/subr_kubsan.c			kubsan
 file kern/subr_log.c
 file kern/subr_percpu.c
Index: kern/kern_malloc.c
===================================================================
RCS file: /cvs/src/sys/kern/kern_malloc.c,v
retrieving revision 1.148
diff -u -p -r1.148 kern_malloc.c
--- kern/kern_malloc.c	14 Aug 2022 01:58:27 -0000	1.148
+++ kern/kern_malloc.c	27 Apr 2023 08:34:00 -0000
@@ -50,6 +50,11 @@
 #include <ddb/db_output.h>
 #endif
 
+#ifdef KASAN
+#include <machine/vmmvar.h>
+#include <sys/kasan.h>
+#endif
+
 static
 #ifndef SMALL_KERNEL
 __inline__
@@ -165,6 +170,11 @@ malloc(size_t size, int type, int flags)
 	int freshalloc;
 	char *savedtype;
 #endif
+#ifdef KASAN
+	size_t origsz = size;
+
+	kasan_add_redzone(&size);
+#endif
 #ifdef KMEMSTATS
 	struct kmemstats *ksp = &kmemstats[type];
 	int wake;
@@ -361,6 +371,7 @@ out:
 
 	TRACEPOINT(uvm, malloc, type, va, size, flags);
 
+	kasan_alloc((vaddr_t)va, origsz, size);
 	return (va);
 }
 
@@ -378,6 +389,10 @@ free(void *addr, int type, size_t freeds
 #ifdef DIAGNOSTIC
 	long alloc;
 #endif
+#ifdef KASAN
+	if (freedsize != 0)
+		kasan_add_redzone(&freedsize);
+#endif
 #ifdef KMEMSTATS
 	struct kmemstats *ksp = &kmemstats[type];
 	int wake;
@@ -494,6 +509,9 @@ free(void *addr, int type, size_t freeds
 #endif
 	XSIMPLEQ_INSERT_TAIL(&kbp->kb_freelist, freep, kf_flist);
 	mtx_leave(&malloc_mtx);
+#ifdef KASAN
+	kasan_free((vaddr_t)addr, size);
+#endif
 #ifdef KMEMSTATS
 	if (wake)
 		wakeup(ksp);
Index: kern/subr_kasan.c
===================================================================
RCS file: kern/subr_kasan.c
diff -N kern/subr_kasan.c
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ kern/subr_kasan.c	28 Apr 2023 08:21:00 -0000
@@ -0,0 +1,598 @@
+/*	$OpenBSD$	*/
+
+#include <sys/param.h>
+#include <sys/proc.h>
+#include <sys/tree.h>
+#include <sys/types.h>
+#include <sys/systm.h>
+
+#include <uvm/uvm_extern.h>
+
+#include <machine/kasan.h>
+#include <machine/cpu.h>
+#include <machine/pmap.h>
+#include <machine/segments.h>
+#include <machine/vmmvar.h>
+
+#include <sys/kasan.h>
+
+#define __RET_ADDR	(vaddr_t)__builtin_return_address(0)
+
+#define ADDR_CROSSES_SCALE_BOUNDARY(addr, size) 		\
+	(addr >> KASAN_SHADOW_SCALE_SHIFT) !=			\
+	    ((addr + size - 1) >> KASAN_SHADOW_SCALE_SHIFT)
+
+void kasan_init(void);
+
+static int kasan_enabled = 0;
+static paddr_t kasan_zero = 0;
+
+static int
+kasan_unsupported(vaddr_t addr)
+{
+	return (addr >= VM_MIN_KERNEL_ADDRESS ||
+	    addr < VM_MAX_KERNEL_ADDRESS);
+}
+
+int
+kasan_enter_shad(vaddr_t sva, paddr_t pa)
+{
+	uint64_t l4idx, l3idx, l2idx, l1idx;
+	pd_entry_t *pd, npte;
+	struct vm_page *ptp, *pptp;
+	paddr_t npa;
+	struct uvm_object *obj;
+	struct pmap *pmap = pmap_kernel();
+
+	if (sva > MAXDSIZ)
+		return ENOMEM;
+
+	l4idx = (sva & L4_MASK) >> L4_SHIFT; /* PML4E idx */
+	l3idx = (sva & L3_MASK) >> L3_SHIFT; /* PDPTE idx */
+	l2idx = (sva & L2_MASK) >> L2_SHIFT; /* PDE idx */
+	l1idx = (sva & L1_MASK) >> L1_SHIFT; /* PTE idx */
+
+	/* Start at PML4 / top level */
+	pd = (pd_entry_t *)pmap->pm_pdir;
+
+	if (pd == NULL)
+		return ENOMEM;
+
+	/* npa = physaddr of PDPT */
+	npa = pd[l4idx] & PMAP_PA_MASK;
+
+	/* Valid PML4e for the 512GB region containing sva? */
+	if (!npa) {
+		/* No valid PML4e - allocate PDPT page and set PML4e */
+		obj = &pmap->pm_obj[2];	/* PML4 UVM object */
+		ptp = uvm_pagealloc(obj, ptp_va2o(sva, 3), NULL,
+		    UVM_PGA_USERESERVE|UVM_PGA_ZERO);
+
+		if (ptp == NULL)
+			return ENOMEM;
+
+		/*
+		 * New PDPT page - we are setting the first entry, so set
+		 * the wired count to 1
+		 */
+		ptp->wire_count = 1;
+
+		/* Calculate phys address of this new PDPT page */
+		npa = VM_PAGE_TO_PHYS(ptp);
+
+		/*
+		 * Higher levels get full perms; specific permissions are
+		 * entered at the lowest level.
+		 */
+		pd[l4idx] = (npa | PG_KW | pg_nx | PG_V);
+
+		pmap->pm_stats.resident_count++;
+
+		pptp = ptp;
+	} else {
+		/* Already allocated PML4e */
+		pptp = PHYS_TO_VM_PAGE(npa);
+	}
+
+	pd = (pd_entry_t *)PMAP_DIRECT_MAP(npa);
+	if (pd == NULL)
+		panic("%s: can't locate PDPT @ pa=0x%llx", __func__,
+		    (uint64_t)npa);
+
+	/* npa = physaddr of PD page */
+	npa = pd[l3idx] & PMAP_PA_MASK;
+
+	/* Valid PDPTe for the 1GB region containing sva? */
+	if (!npa) {
+		/* No valid PDPTe - allocate PD page and set PDPTe */
+		obj = &pmap->pm_obj[1];	/* PDPT UVM object */
+		ptp = uvm_pagealloc(obj, ptp_va2o(sva, 2), NULL,
+		    UVM_PGA_USERESERVE|UVM_PGA_ZERO);
+
+		if (ptp == NULL)
+			return ENOMEM;
+
+		/*
+		 * New PD page - we are setting the first entry, so set
+		 * the wired count to 1
+		 */
+		ptp->wire_count = 1;
+		pptp->wire_count++;
+
+		npa = VM_PAGE_TO_PHYS(ptp);
+
+		/*
+		 * Higher levels get full perms; specific permissions are
+		 * entered at the lowest level.
+		 */
+		pd[l3idx] = (npa | PG_KW | pg_nx | PG_V);
+
+		pmap->pm_stats.resident_count++;
+
+		pptp = ptp;
+	} else {
+		/* Already allocated PDPTe */
+		pptp = PHYS_TO_VM_PAGE(npa);
+	}
+
+	pd = (pd_entry_t *)PMAP_DIRECT_MAP(npa);
+	if (pd == NULL)
+		panic("%s: can't locate PD page @ pa=0x%llx", __func__,
+		    (uint64_t)npa);
+
+	/* npa = physaddr of PT page */
+	npa = pd[l2idx] & PMAP_PA_MASK;
+
+	/* Valid PDE for the 2MB region containing sva? */
+	if (!npa) {
+		/* No valid PDE - allocate PT page and set PDE */
+		obj = &pmap->pm_obj[0];	/* PDE UVM object */
+		ptp = uvm_pagealloc(obj, ptp_va2o(sva, 1), NULL,
+		    UVM_PGA_USERESERVE|UVM_PGA_ZERO);
+
+		if (ptp == NULL)
+			return ENOMEM;
+
+		pptp->wire_count++;
+
+		npa = VM_PAGE_TO_PHYS(ptp);
+
+		/*
+		 * Higher level get full perms; specific permissions are
+		 * entered at the lowest level.
+		 */
+		pd[l2idx] = (npa | PG_KW | pg_g_kern | pg_nx | PG_V);
+
+		pmap->pm_stats.resident_count++;
+
+	} else {
+		/* Find final ptp */
+		ptp = PHYS_TO_VM_PAGE(npa);
+		if (ptp == NULL)
+			panic("%s: ptp page vanished?", __func__);
+	}
+
+	pd = (pd_entry_t *)PMAP_DIRECT_MAP(npa);
+	if (pd == NULL)
+		panic("%s: can't locate PT page @ pa=0x%llx", __func__,
+		    (uint64_t)npa);
+
+	npte = pa | PG_KW | pg_nx | PG_V;
+
+	if (pd[l1idx] == 0) {
+		ptp->wire_count++;
+		pmap->pm_stats.resident_count++;
+	} else {
+		/* XXX flush ept */
+	}
+
+	pd[l1idx] = npte;
+
+	return 0;
+}
+
+void
+kasan_enter_shad_multi(vaddr_t va, size_t sz)
+{
+	struct uvm_object *obj;
+	struct vm_page *ptp;
+	struct pmap *pmap = pmap_kernel();
+	size_t ssz, spgs, i;
+	vaddr_t sva, zva;
+
+	if (kasan_zero == 0) {
+		zva = KASAN_SHADOW_START - 8;
+		obj = &pmap->pm_obj[0];
+		ptp = uvm_pagealloc(obj, ptp_va2o((vaddr_t)zva, 0), NULL,
+		    UVM_PGA_USERESERVE|UVM_PGA_ZERO);
+
+		if (ptp == NULL)
+			panic("no memory");
+
+		pmap->pm_stats.resident_count++;
+
+		kasan_zero = VM_PAGE_TO_PHYS(ptp);
+		memset((char *)zva, 0x80, PAGE_SIZE);
+	}
+
+
+	sva = (vaddr_t)kasan_addr_to_shad(va);
+	ssz = (sz + KASAN_SHADOW_SCALE_SIZE - 1) / KASAN_SHADOW_SCALE_SIZE;
+	sva = (va / PAGE_SIZE) * PAGE_SIZE;
+	spgs = (ssz + PAGE_SIZE - 1) / PAGE_SIZE;
+
+	for (i = 0; i < spgs; i++)
+		if (kasan_enter_shad(sva + i * PAGE_SIZE, kasan_zero))
+			panic("failed to create kasa page at 0x%lx", sva +
+			    i * PAGE_SIZE);
+}
+
+/*
+ * Create the shadow mapping. We don't create the 'User' area, because we
+ * exclude it from the monitoring. The 'Main' area is created dynamically
+ * in pmap_growkernel.
+ */
+void
+kasan_init(void)
+{
+	kasan_enabled = 1;
+	
+
+	/* Call the ASAN constructors. */
+	kasan_ctors();
+}
+
+static void
+kasan_report(vaddr_t addr, size_t size, int write, vaddr_t rip)
+{
+	printf("KASAN: unregistered access at 0x%lx: "
+	    "%s of %lu byte%s from 0x%lx\n", rip,
+	    (write ? "write" : "read"), size, (size > 1 ? "s" : ""), addr);
+}
+
+static void
+kasan_shadow_fill(vaddr_t addr, size_t size, uint8_t val)
+{
+	char *shad;
+
+	if (!kasan_enabled)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	KASSERT(addr % KASAN_SHADOW_SCALE_SIZE == 0);
+	KASSERT(size % KASAN_SHADOW_SCALE_SIZE == 0);
+
+	shad = kasan_addr_to_shad(addr);
+	size = size >> KASAN_SHADOW_SCALE_SHIFT;
+
+	__builtin_memset(shad, val, size);
+}
+
+static inline void
+kasan_shadow_1byte_markvalid(vaddr_t addr)
+{
+	char *byte = kasan_addr_to_shad(addr);
+	char last = (addr & KASAN_SHADOW_MASK) + 1;
+
+	*byte = last;
+}
+
+void
+kasan_add_redzone(size_t *size)
+{
+	*size = roundup(*size, KASAN_SHADOW_SCALE_SIZE);
+	*size += KASAN_SHADOW_SCALE_SIZE;
+}
+
+static void
+kasan_markmem(vaddr_t addr, size_t size, int valid)
+{
+	size_t i;
+
+	KASSERT(addr % KASAN_SHADOW_SCALE_SIZE == 0);
+
+	if (valid) {
+		for (i = 0; i < size; i++)
+			kasan_shadow_1byte_markvalid(addr + i);
+	} else {
+		KASSERT(size % KASAN_SHADOW_SCALE_SIZE == 0);
+		kasan_shadow_fill(addr, size, KASAN_MEMORY_REDZONE);
+	}
+}
+
+void
+kasan_alloc(vaddr_t addr, size_t size, size_t sz_with_redz)
+{
+	if (!kasan_enabled)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	kasan_markmem(addr, sz_with_redz, 0);
+	kasan_markmem(addr, size, 1);
+}
+
+void
+kasan_free(vaddr_t addr, size_t sz_with_redz)
+{
+	if (!kasan_enabled)
+		return;
+	if (sz_with_redz == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	kasan_markmem(addr, sz_with_redz, 1);
+}
+
+static inline int
+kasan_shadow_1byte_isvalid(vaddr_t addr)
+{
+	char *byte = kasan_addr_to_shad(addr);
+	char last = (addr & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_2byte_isvalid(vaddr_t addr)
+{
+	char *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 2)) {
+		return (kasan_shadow_1byte_isvalid(addr) &&
+		    kasan_shadow_1byte_isvalid(addr + 1));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 1) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_4byte_isvalid(vaddr_t addr)
+{
+	char *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 4)) {
+		return (kasan_shadow_2byte_isvalid(addr) &&
+		    kasan_shadow_2byte_isvalid(addr + 2));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 3) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_8byte_isvalid(vaddr_t addr)
+{
+	int8_t *byte, last;
+
+	if (ADDR_CROSSES_SCALE_BOUNDARY(addr, 8)) {
+		return (kasan_shadow_4byte_isvalid(addr) &&
+		    kasan_shadow_4byte_isvalid(addr + 4));
+	}
+
+	byte = kasan_addr_to_shad(addr);
+	last = ((addr + 7) & KASAN_SHADOW_MASK) + 1;
+
+	return (*byte == 0 || last <= *byte);
+}
+
+static inline int
+kasan_shadow_Nbyte_isvalid(vaddr_t addr, size_t size)
+{
+	size_t i;
+
+	for (i = 0; i < size; i++) {
+		if (!kasan_shadow_1byte_isvalid(addr + i))
+			return 0;
+	}
+
+	return 1;
+}
+
+static inline void
+kasan_shadow_check(unsigned long addr, size_t size, int write, vaddr_t retaddr)
+{
+	int valid;
+
+	if (!kasan_enabled)
+		return;
+	if (size == 0)
+		return;
+	if (kasan_unsupported(addr))
+		return;
+
+	if (__builtin_constant_p(size)) {
+		switch (size) {
+		case 1:
+			valid = kasan_shadow_1byte_isvalid(addr);
+			break;
+		case 2:
+			valid = kasan_shadow_2byte_isvalid(addr);
+			break;
+		case 4:
+			valid = kasan_shadow_4byte_isvalid(addr);
+			break;
+		case 8:
+			valid = kasan_shadow_8byte_isvalid(addr);
+			break;
+		default:
+			valid = kasan_shadow_Nbyte_isvalid(addr, size);
+			break;
+		}
+	} else {
+		valid = kasan_shadow_Nbyte_isvalid(addr, size);
+	}
+
+	if (!valid) {
+		kasan_report(addr, size, write, retaddr);
+	}
+}
+
+void *
+kasan_memcpy(void *dst, const void *src, size_t len)
+{
+	kasan_shadow_check((vaddr_t)src, len, 0, __RET_ADDR);
+	kasan_shadow_check((vaddr_t)dst, len, 1, __RET_ADDR);
+	return __builtin_memcpy(dst, src, len);
+}
+
+int
+kasan_memcmp(const void *b1, const void *b2, size_t len)
+{
+	kasan_shadow_check((vaddr_t)b1, len, 0, __RET_ADDR);
+	kasan_shadow_check((vaddr_t)b2, len, 0, __RET_ADDR);
+	return __builtin_memcmp(b1, b2, len);
+}
+
+void *
+kasan_memset(void *b, int c, size_t len)
+{
+	kasan_shadow_check((vaddr_t)b, len, 1, __RET_ADDR);
+	return __builtin_memset(b, c, len);
+}
+
+static void
+kasan_register_global(struct __asan_global *global)
+{
+	size_t aligned_size = roundup(global->size, KASAN_SHADOW_SCALE_SIZE);
+
+	/* Poison the redzone following the var. */
+	kasan_shadow_fill((vaddr_t)((uintptr_t)global->beg + aligned_size),
+	    global->size_with_redzone - aligned_size, KASAN_GLOBAL_REDZONE);
+}
+
+void
+__asan_register_globals(struct __asan_global *globals, size_t size)
+{
+printf("%s\n", __func__);
+	size_t i;
+	for (i = 0; i < size; i++) {
+		kasan_register_global(&globals[i]);
+	}
+}
+
+void
+__asan_unregister_globals(struct __asan_global *globals, size_t size)
+{
+printf("%s\n", __func__);
+}
+
+#define ASAN_LOAD_STORE(size)					\
+	void __asan_load##size(unsigned long);			\
+	void __asan_load##size(unsigned long addr)		\
+	{							\
+		kasan_shadow_check(addr, size, 0, __RET_ADDR);\
+	} 							\
+	void __asan_load##size##_noabort(unsigned long);	\
+	void __asan_load##size##_noabort(unsigned long addr)	\
+	{							\
+		kasan_shadow_check(addr, size, 0, __RET_ADDR);\
+	}							\
+	void __asan_store##size(unsigned long);			\
+	void __asan_store##size(unsigned long addr)		\
+	{							\
+		kasan_shadow_check(addr, size, 1, __RET_ADDR);\
+	}							\
+	void __asan_store##size##_noabort(unsigned long);	\
+	void __asan_store##size##_noabort(unsigned long addr)	\
+	{							\
+		kasan_shadow_check(addr, size, 1, __RET_ADDR);\
+	}
+
+ASAN_LOAD_STORE(1);
+ASAN_LOAD_STORE(2);
+ASAN_LOAD_STORE(4);
+ASAN_LOAD_STORE(8);
+ASAN_LOAD_STORE(16);
+
+void
+__asan_loadN(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 0, __RET_ADDR);
+}
+
+void
+__asan_loadN_noabort(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 0, __RET_ADDR);
+}
+
+void
+__asan_storeN(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 1, __RET_ADDR);
+}
+
+void
+__asan_storeN_noabort(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	kasan_shadow_check(addr, size, 1, __RET_ADDR);
+}
+
+void
+__asan_handle_no_return(void)
+{
+printf("%s\n", __func__);
+	/* nothing */
+}
+
+void
+__asan_poison_stack_memory(const void *addr, size_t size)
+{
+printf("%s\n", __func__);
+	vaddr_t va = (vaddr_t)addr;
+	KASSERT(va % KASAN_SHADOW_SCALE_SIZE == 0);
+	kasan_shadow_fill(va, size, KASAN_USE_AFTER_SCOPE);
+}
+
+void
+__asan_unpoison_stack_memory(const void *addr, size_t size)
+{
+printf("%s\n", __func__);
+	vaddr_t va = (vaddr_t)addr;
+	KASSERT(va % KASAN_SHADOW_SCALE_SIZE == 0);
+	kasan_shadow_fill(va, size, 0);
+}
+
+void
+__asan_alloca_poison(unsigned long addr, size_t size)
+{
+printf("%s\n", __func__);
+	panic("%s: impossible!", __func__);
+}
+
+void
+__asan_allocas_unpoison(const void *stack_top, const void *stack_bottom)
+{
+printf("%s\n", __func__);
+	panic("%s: impossible!", __func__);
+}
+
+#define ASAN_SET_SHADOW(byte) \
+	void __asan_set_shadow_##byte(void *, size_t);			\
+	void __asan_set_shadow_##byte(void *addr, size_t size)		\
+	{								\
+		__builtin_memset((void *)addr, 0x##byte, size);		\
+	}
+
+ASAN_SET_SHADOW(00);
+ASAN_SET_SHADOW(f1);
+ASAN_SET_SHADOW(f2);
+ASAN_SET_SHADOW(f3);
+ASAN_SET_SHADOW(f5);
+ASAN_SET_SHADOW(f8);
Index: sys/kasan.h
===================================================================
RCS file: sys/kasan.h
diff -N sys/kasan.h
--- /dev/null	1 Jan 1970 00:00:00 -0000
+++ sys/kasan.h	27 Apr 2023 12:15:52 -0000
@@ -0,0 +1,82 @@
+/*	$OpenBSD$	*/
+
+#ifndef _SYS_KASAN_H_
+#define _SYS_KASAN_H_
+
+#define KASAN_SHADOW_SCALE_SHIFT	3
+#define KASAN_SHADOW_SCALE_SIZE		(1UL << KASAN_SHADOW_SCALE_SHIFT)
+#define KASAN_SHADOW_MASK		(KASAN_SHADOW_SCALE_SIZE - 1)
+
+#define KASAN_SHADOW_SIZE	(VM_MAX_KERNEL_ADDRESS - VM_MIN_KERNEL_ADDRESS)
+#define KASAN_SHADOW_START	(VA_SIGN_NEG((L4_SLOT_KASAN * NBPD_L4)))
+#define KASAN_SHADOW_END	(KASAN_SHADOW_START + KASAN_SHADOW_SIZE)
+
+/* Our redzone values. */
+#define KASAN_GLOBAL_REDZONE	0xFA
+#define KASAN_MEMORY_REDZONE	0xFB
+
+/* Stack redzone shadow values. Part of the compiler ABI. */
+#define KASAN_STACK_LEFT	0xF1
+#define KASAN_STACK_MID		0xF2
+#define KASAN_STACK_RIGHT	0xF3
+#define KASAN_STACK_PARTIAL	0xF4
+#define KASAN_USE_AFTER_SCOPE	0xF8
+
+inline char *
+kasan_addr_to_shad(vaddr_t va)
+{
+	return (char *)(KASAN_SHADOW_START +
+	    ((va - VM_MIN_KERNEL_ADDRESS) >> KASAN_SHADOW_SCALE_SHIFT));
+}
+
+void	 kasan_add_redzone(size_t *);
+void	 kasan_alloc(vaddr_t, size_t, size_t);
+void	 kasan_free(vaddr_t, size_t);
+
+struct __asan_global;
+
+void __asan_register_globals(struct __asan_global *, size_t);
+void __asan_unregister_globals(struct __asan_global *, size_t);
+
+void __asan_loadN(unsigned long, size_t);
+void __asan_loadN_noabort(unsigned long, size_t);
+void __asan_storeN(unsigned long, size_t);
+void __asan_storeN_noabort(unsigned long, size_t);
+void __asan_handle_no_return(void);
+void __asan_poison_stack_memory(const void *, size_t);
+void __asan_unpoison_stack_memory(const void *, size_t);
+void __asan_alloca_poison(unsigned long, size_t);
+void __asan_allocas_unpoison(const void *, const void *);
+
+#if defined(__clang__) && (__clang_major__ - 0 >= 6)
+#define ASAN_ABI_VERSION	8
+#elif __GNUC_PREREQ__(7, 1) && !defined(__clang__)
+#define ASAN_ABI_VERSION	8
+#elif __GNUC_PREREQ__(6, 1) && !defined(__clang__)
+#define ASAN_ABI_VERSION	6
+#else
+#error "Unsupported compiler version"
+#endif
+
+/*
+ * Part of the compiler ABI.
+ */
+struct __asan_global_source_location {
+	const char *filename;
+	int line_no;
+	int column_no;
+};
+struct __asan_global {
+	const void *beg;		/* address of the global variable */
+	size_t size;			/* size of the global variable */
+	size_t size_with_redzone;	/* size with the redzone */
+	const void *name;		/* name of the variable */
+	const void *module_name;	/* name of the module where the var is declared */
+	unsigned long has_dynamic_init;	/* the var has dyn initializer (c++) */
+	struct __asan_global_source_location *location;
+#if ASAN_ABI_VERSION >= 7
+	uintptr_t odr_indicator;	/* the address of the ODR indicator symbol */
+#endif
+};
+
+#endif /* !_SYS_KASAN_H_ */
Index: sys/systm.h
===================================================================
RCS file: /cvs/src/sys/sys/systm.h,v
retrieving revision 1.161
diff -u -p -r1.161 systm.h
--- sys/systm.h	31 Jan 2023 15:18:56 -0000	1.161
+++ sys/systm.h	27 Apr 2023 08:34:03 -0000
@@ -383,10 +383,20 @@ extern int (*mountroot)(void);
 
 #include <lib/libkern/libkern.h>
 
+#ifdef KASAN
+void	*kasan_memset(void *, int, size_t);
+int	kasan_memcmp(const void *, const void *, size_t);
+void	*kasan_memcpy(void *, const void *, size_t);
+#define bzero(b, n)		kasan_memset((b), 0, (n))
+#define memcmp(b1, b2, n)	kasan_memcmp((b1), (b2), (n))
+#define memcpy(d, s, n)		kasan_memcpy((d), (s), (n))
+#define memset(b, c, n)		kasan_memset((b), (c), (n))
+#else
 #define bzero(b, n)		__builtin_bzero((b), (n))
 #define memcmp(b1, b2, n)	__builtin_memcmp((b1), (b2), (n))
 #define memcpy(d, s, n)		__builtin_memcpy((d), (s), (n))
 #define memset(b, c, n)		__builtin_memset((b), (c), (n))
+#endif
 #if (defined(__GNUC__) && __GNUC__ >= 4)
 #define memmove(d, s, n)	__builtin_memmove((d), (s), (n))
 #endif
Index: uvm/uvm_page.c
===================================================================
RCS file: /cvs/src/sys/uvm/uvm_page.c,v
retrieving revision 1.171
diff -u -p -r1.171 uvm_page.c
--- uvm/uvm_page.c	11 Apr 2023 00:45:09 -0000	1.171
+++ uvm/uvm_page.c	27 Apr 2023 12:26:07 -0000
@@ -707,6 +707,7 @@ uvm_pagealloc_pg(struct vm_page *pg, str
 		flags |= PQ_ANON;
 	} else if (obj)
 		uvm_pageinsert(pg);
+printf("uvm_pagealloc_pg behind unused branches\n");
 	atomic_setbits_int(&pg->pg_flags, flags);
 #if defined(UVM_PAGE_TRKOWN)
 	pg->owner_tag = NULL;
@@ -907,6 +908,7 @@ uvm_pagealloc(struct uvm_object *obj, vo
 	if (flags & UVM_PGA_ZERO)
 		pmr_flags |= UVM_PLA_ZERO;
 	TAILQ_INIT(&pgl);
+printf("uvm_pagealloc:  before getpages\n");
 	if (uvm_pmr_getpages(1, 0, 0, 1, 0, 1, pmr_flags, &pgl) != 0)
 		goto fail;
 
